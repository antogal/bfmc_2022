{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px # this is another plotting library for interactive plot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, manifold # we will use the metrics and manifold learning modules from scikit-learn\n",
    "from pathlib import Path # to interact with file paths\n",
    "from PIL import Image # to interact with images\n",
    "from tqdm import tqdm # progress bar\n",
    "from pprint import pprint # pretty print (useful for a more readable print of objects like lists or dictionaries)\n",
    "from IPython.display import clear_output # to clear the output of the notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2 as cv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTROL\n",
    "num_channels = 1\n",
    "SIZE = (32,32)\n",
    "model_name = 'models/stop_line_estimator.pt'\n",
    "onnx_model_path = \"models/stop_line_estimator.onnx\"\n",
    "max_load = 250_000 #note: it will be ~50% more since training points with pure road gets flipped with inverted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Net and create Detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK ARCHITECTURE\n",
    "\n",
    "class StopLineEstimator(nn.Module):\n",
    "    def __init__(self, out_dim=4, channels=1): \n",
    "        super().__init__()\n",
    "        ### Convoluational layers\n",
    "        prob = 0.2\n",
    "        self.conv = nn.Sequential( #in = (SIZE)\n",
    "            nn.Conv2d(channels, 4, kernel_size=5, stride=1), #out = 28\n",
    "            nn.ReLU(True),\n",
    "            # nn.Dropout(p=prob),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), #out=14\n",
    "            nn.BatchNorm2d(4),\n",
    "            # nn.Dropout(p=prob),\n",
    "            nn.Conv2d(4, 4, kernel_size=5, stride=1), #out = 10\n",
    "            nn.ReLU(True),\n",
    "            # nn.Dropout(p=prob),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), #out=5\n",
    "            # nn.Dropout(p=prob),\n",
    "            nn.Conv2d(4, 32, kernel_size=5, stride=1), #out = 1\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.flat = nn.Flatten()\n",
    "        ### Linear sections\n",
    "        self.lin = nn.Sequential(\n",
    "            #normalize\n",
    "            # nn.BatchNorm1d(3*3*4),\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=1*1*32, out_features=16),\n",
    "            nn.ReLU(True),\n",
    "            # nn.Tanh(),\n",
    "            nn.Linear(in_features=16, out_features=out_dim),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "stop_line_estimator = StopLineEstimator(out_dim=1,channels=num_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32, 32])\n",
      "out shape: torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# TEST NET INPUTS/OUTPUTS\n",
    "#show the image with opencv\n",
    "img = cv.imread('tests/test_img.jpg')\n",
    "img = cv.resize(img, SIZE)\n",
    "if num_channels == 1:\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "#convert to tensor\n",
    "img = torch.from_numpy(img).float()\n",
    "img = img.permute(2,0,1)\n",
    "#add dimension\n",
    "img = img.unsqueeze(0).to(device)\n",
    "print(img.shape)\n",
    "\n",
    "stop_line_estimator.eval()\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    output = stop_line_estimator(img)\n",
    "    print(f'out shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG LOADER AND AUGMENTATION\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "from time import time, sleep\n",
    "\n",
    "\n",
    "def load_and_augment_img(img, folder='training_imgs'):\n",
    "    #convert to gray\n",
    "    img = cv.resize(img, (4*SIZE[1], 4*SIZE[0]))\n",
    "\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    #create random ellipses to simulate light from the sun\n",
    "    light = np.zeros(img.shape, dtype=np.uint8)\n",
    "    #add ellipses\n",
    "    for j in range(2):\n",
    "        cent = (randint(0, img.shape[0]), randint(0, img.shape[1]))\n",
    "        axes_length = (randint(10//4, 50//4), randint(50//4, 300//4))\n",
    "        angle = randint(0, 360)\n",
    "        light = cv.ellipse(light, cent, axes_length, angle, 0, 360, 255, -1)\n",
    "    #create an image of random white and black pixels\n",
    "    light = cv.blur(light, (50,50))\n",
    "    noise = randint(0, 2, size=img.shape, dtype=np.uint8)*255\n",
    "    light = cv.subtract(light, noise)\n",
    "    light = np.clip(light, 0, 51)\n",
    "    light *= 5\n",
    "    #add light to the image\n",
    "    img = cv.add(img, light)\n",
    "\n",
    "    # cv.imshow('light', light)\n",
    "    # if cv.waitKey(0) == ord('q'):\n",
    "    #     break\n",
    "\n",
    "    #blur the image\n",
    "    img = cv.blur(img, (randint(1, 5), randint(1, 5)))\n",
    "\n",
    "    # cut the top third of the image, let it 640x320\n",
    "    img = img[int(img.shape[0]*(2/5)):,:] ################################# 2/5 frame[int(frame.shape[0]*(2/5)):,:]\n",
    "    # assert img.shape == (320,640), f'img shape cut = {img.shape}'\n",
    "\n",
    "    #edges\n",
    "    img = cv.resize(img, (2*SIZE[1], 2*SIZE[0]))\n",
    "\n",
    "    # erosion and dilation\n",
    "    # r = randint(0, 5)\n",
    "    # if r == 0:\n",
    "    #     #dilate\n",
    "    #     kernel = np.ones((randint(1, 5), randint(1, 5)), np.uint8)\n",
    "    #     img = cv.dilate(img, kernel, iterations=1)\n",
    "    # elif r == 1:\n",
    "    #     #erode\n",
    "    #     kernel = np.ones((randint(1, 5), randint(1, 5)), np.uint8)\n",
    "    #     img = cv.erode(img, kernel, iterations=1)\n",
    "\n",
    "\n",
    "    #edges    \n",
    "    img = cv.Canny(img, 100, 200)\n",
    "\n",
    "    #blur\n",
    "    img = cv.blur(img, (3,3))\n",
    "\n",
    "    #resize \n",
    "    img = cv.resize(img, SIZE)\n",
    "\n",
    "    # #get max brightness\n",
    "    # max_brightness = np.max(img)\n",
    "    # ratio = 255.0/max_brightness\n",
    "    # #normalize\n",
    "    # img = (img*ratio).astype(np.uint8)\n",
    "\n",
    "    #add random tilt\n",
    "    max_offset = 1\n",
    "    offset = randint(-max_offset, max_offset)\n",
    "    img = np.roll(img, offset, axis=0)\n",
    "    if offset > 0:\n",
    "        img[:offset, :] = 0 #randint(0,255)\n",
    "    elif offset < 0:\n",
    "        img[offset:, :] = 0 # randint(0,255)\n",
    "    \n",
    "    # #add salt and pepper noise\n",
    "    # sp_noise = randint(0, 4, size=img.shape, dtype=np.uint8)\n",
    "    # sp_noise = np.where(sp_noise == 0, np.zeros_like(img), 255*np.ones_like(img))\n",
    "    # # img = cv.bitwise_xor(img, sp_noise)\n",
    "\n",
    "\n",
    "    # #reduce contrast\n",
    "    # const = np.random.uniform(0.1,0.8)\n",
    "    # # if np.random.uniform() > .5:\n",
    "    # #     const = const*0.2\n",
    "    # img = 127*(1-const) + img*const\n",
    "    # img = img.astype(np.uint8)\n",
    "\n",
    "    #add noise \n",
    "    std = 60\n",
    "    std = randint(1, std)\n",
    "    noisem = randint(0, std, img.shape, dtype=np.uint8)\n",
    "    img = cv.subtract(img, noisem)\n",
    "    noisep = randint(0, std, img.shape, dtype=np.uint8)\n",
    "    img = cv.add(img, noisep)\n",
    "\n",
    "    # #add random brightness\n",
    "    # max_brightness = 60\n",
    "    # brightness = randint(-max_brightness, max_brightness)\n",
    "    # if brightness > 0:\n",
    "    #     img = cv.add(img, brightness)\n",
    "    # elif brightness < 0:\n",
    "    #     img = cv.subtract(img, -brightness)\n",
    "\n",
    "    # #blur \n",
    "    # img = cv.blur(img, (randint(1,3),randint(1,3)))\n",
    "\n",
    "    # # invert color\n",
    "    # if np.random.uniform(0, 1) > 0.6:\n",
    "    #     img = cv.bitwise_not(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "cv.namedWindow('img', cv.WINDOW_NORMAL)\n",
    "# cv.setWindowProperty('img', cv.WND_PROP_FULLSCREEN, cv.WINDOW_FULLSCREEN)\n",
    "\n",
    "for i in range(5000):\n",
    "    img = cv.imread(os.path.join('training_imgs', f'img_{i+1}.png'))\n",
    "    img = load_and_augment_img(img)\n",
    "    cv.imshow('img', img)\n",
    "    key = cv.waitKey(100)\n",
    "    if key == ord('q') or key == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET CLASS\n",
    "#TODO add negative examples: inside intersection, in normal road with high curvature\n",
    "class CsvDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None, max_load=1000, channels=3):\n",
    "        self.transform = transform\n",
    "        self.folder = folder\n",
    "        self.data = []\n",
    "        self.channels = channels\n",
    "\n",
    "        junction_images_indexes = []\n",
    "        tot_lines = 0\n",
    "        with open(folder+'/classification_labels.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            tot_lines = len(lines)\n",
    "            for i,line in enumerate(lines):\n",
    "                if line == '1,0,0,0,0,0,0,1,0,0,0,0,0,0,0':\n",
    "                    junction_images_indexes.append(i)\n",
    "        junction_imgs_mask = np.zeros(tot_lines, dtype=np.bool)\n",
    "        junction_imgs_mask[junction_images_indexes] = True\n",
    "\n",
    "        with open(folder+'/regression_labels.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            # Get x and y values from each line and append to self.data\n",
    "            max_load = min(max_load, len(lines))\n",
    "            self.all_imgs = torch.zeros((max_load, SIZE[1], SIZE[0], channels), dtype=torch.uint8)\n",
    "\n",
    "            cv.namedWindow('img', cv.WINDOW_NORMAL)\n",
    "            all_img_idx = 0\n",
    "            for i in tqdm(range(200, max_load)): #start from 200 since first imgs have wrong labels\n",
    "            # for i in range(max_load):\n",
    "                #label\n",
    "                line = lines[i]\n",
    "                dist = line.split(',')\n",
    "                #distance is the third element of the label data\n",
    "                dist_label = np.array([float(dist[2])], dtype=np.float32)\n",
    "            \n",
    "                MAX_DIST = 0.7\n",
    "                #keep only small distanaces, avoid junctions\n",
    "                if dist_label < MAX_DIST and not junction_imgs_mask[i]: \n",
    "                    # print(f'Sample {i},  idx = {all_img_idx},  dist = {dist_label}')\n",
    "                    if dist_label < -0.01:\n",
    "                        dist_label = MAX_DIST - dist_label\n",
    "                    #img \n",
    "                    img = cv.imread(os.path.join(folder, f'img_{i+1}.png'))\n",
    "                    img = load_and_augment_img(img)\n",
    "                    if i < 100:\n",
    "                        cv.imshow('img', img)\n",
    "                        cv.waitKey(1)\n",
    "                        if i == 99:\n",
    "                            cv.destroyAllWindows()\n",
    "                    #add a dimension to the image\n",
    "                    img = img[:, :,np.newaxis]\n",
    "                    self.all_imgs[all_img_idx] = torch.from_numpy(img)\n",
    "                    self.data.append(dist_label)\n",
    "                    all_img_idx += 1\n",
    "\n",
    "            self.all_imgs = self.all_imgs[:all_img_idx]\n",
    "            self.data = np.array(self.data)\n",
    "\n",
    "            print(f'\\nall imgs: {self.all_imgs.shape}')\n",
    "            print(f'data: {self.data.shape}')\n",
    "\n",
    "    def __len__(self):\n",
    "        # The length of the dataset is simply the length of the self.data list\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # img = read_image(os.path.join(self.folder, f'img_{idx+1}.png'))\n",
    "        # img = img.float()\n",
    "        img = self.all_imgs[idx]\n",
    "        img = img.permute(2, 0, 1).float()\n",
    "        value = self.data[idx]\n",
    "        return img, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 244982/244982 [02:24<00:00, 1695.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "all imgs: torch.Size([45113, 32, 32, 1])\n",
      "data: (45113, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#create dataset #takes a long time but then training is faster\n",
    "train_dataset = CsvDataset('training_imgs', max_load=max_load, channels=num_channels)\n",
    "#split dataset into train and val\n",
    "train_size = int(0.9*len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8192, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8192, 1, 32, 32])\n",
      "torch.Size([8192, 1])\n"
     ]
    }
   ],
   "source": [
    "#test dataloader\n",
    "sample = next(iter(train_dataloader))\n",
    "print(sample[0].shape)\n",
    "print(sample[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING FUNCTION\n",
    "def train_epoch(model, dataloader, regr_loss_fn, optimizer, L1_lambda=0.0, L2_lambda=0.0,  device=device):\n",
    "    # Set the model to training mode\n",
    "    model.train() #train\n",
    "    # Initialize the loss\n",
    "    dist_losses = []\n",
    "\n",
    "    # Loop over the training batches\n",
    "    for (input, regr_label) in tqdm(dataloader):\n",
    "        # Move the input and target data to the selected device\n",
    "        input, regr_label =input.to(device), regr_label.to(device)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the output\n",
    "        output = model(input)\n",
    "\n",
    "        #regression\n",
    "        dist = output[:, 0]\n",
    "\n",
    "        dist_label = regr_label[:, 0]\n",
    "\n",
    "        # Compute the losses\n",
    "        dist_loss = 1.0*regr_loss_fn(dist, dist_label)\n",
    "    \n",
    "        #L1 regularization\n",
    "        L1_norm = sum(p.abs().sum() for p in model.conv.parameters())\n",
    "        L1_loss = L1_lambda * L1_norm \n",
    "        #L2 regularization\n",
    "        L2_norm = sum(p.pow(2).sum() for p in model.conv.parameters())\n",
    "        L2_loss = L2_lambda * L2_norm\n",
    "\n",
    "        loss = dist_loss + L1_loss + L2_loss\n",
    "\n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #batch loss\n",
    "        dist_losses.append(dist_loss.detach().cpu().numpy())\n",
    "\n",
    "    return np.mean(dist_losses)\n",
    "\n",
    "# VALIDATION FUNCTION\n",
    "def val_epoch(stop_line_estimator, val_dataloader, regr_loss_fn, device=device):\n",
    "    stop_line_estimator.eval()\n",
    "    dist_losses = []\n",
    "    for (input, regr_label) in tqdm(val_dataloader):\n",
    "        input, regr_label =input.to(device), regr_label.to(device)\n",
    "        output = stop_line_estimator(input)\n",
    "        regr_out = output\n",
    "        dist = regr_out[:, 0]\n",
    "        dist_label = regr_label[:, 0]\n",
    "        dist_loss = 1.0*regr_loss_fn(dist, dist_label)\n",
    "        dist_losses.append(dist_loss.detach().cpu().numpy())\n",
    "    return np.mean(dist_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  80/80 -> dist loss: 0.1372\n",
      "Validation dist loss: 0.1486\n"
     ]
    }
   ],
   "source": [
    "# TRAINING \n",
    "#parameters\n",
    "lr = 0.001 #0.005\n",
    "epochs = 80\n",
    "#regularization is applied only to convolutional section, add weight decay to apply it to all layers\n",
    "L1_lambda = 5e-4 #0.001 \n",
    "L2_lambda = 2e-2 #2e-2\n",
    "optimizer = torch.optim.Adam(stop_line_estimator.parameters(), lr=lr, weight_decay=9e-5) #wd = 2e-3# 3e-5\n",
    "\n",
    "# regr_loss_fn = nn.MSELoss()\n",
    "regr_loss_fn = nn.L1Loss()\n",
    "for epoch in range(epochs):\n",
    "    # try:\n",
    "    if True:\n",
    "        dist_loss = train_epoch(stop_line_estimator, train_dataloader, regr_loss_fn, optimizer, L1_lambda, L2_lambda, device)\n",
    "        val_dist_loss = val_epoch(stop_line_estimator, val_dataloader, regr_loss_fn, device)\n",
    "        clear_output(wait=True)\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    #     torch.cuda.empty_cache()\n",
    "    #     continue\n",
    "    print(f\"Epoch  {epoch+1}/{epochs} -> dist loss: {dist_loss:.4f}\\nValidation dist loss: {val_dist_loss:.4f}\")\n",
    "    # print(f\"lateral_dist_loss: {dist_loss}\")\n",
    "    # print(f\"curv_loss: {curv_loss}\")\n",
    "    torch.save(stop_line_estimator.state_dict(), model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:00<00:00, 216.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val dist_loss: 0.14908799529075623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE ON TEST SET (UNSEEN DATA)\n",
    "stop_line_estimator.load_state_dict(torch.load(model_name))\n",
    "print(f\"Val dist_loss: {val_epoch(stop_line_estimator, val_dataloader, regr_loss_fn, device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 5, 5)\n",
      "(4, 4, 5, 5)\n",
      "(32, 4, 5, 5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x144 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# VISUALIZE CONVOLUTIONAL FILTERS\n",
    "conv_layers = []\n",
    "children = list(stop_line_estimator.children())\n",
    "for i in range(len(children)):\n",
    "    if isinstance(children[i], nn.Conv2d):\n",
    "        conv_layers.append(children[i])\n",
    "    elif isinstance(children[i], nn.Sequential):\n",
    "        for child in children[i].children():\n",
    "            if isinstance(child, nn.Conv2d):\n",
    "                conv_layers.append(child)\n",
    "\n",
    "c0 = conv_layers[0].weight.data.cpu().numpy()\n",
    "c1 = conv_layers[1].weight.data.cpu().numpy()\n",
    "c2 = conv_layers[2].weight.data.cpu().numpy()\n",
    "\n",
    "def plot_nchw_data(data, h_num, v_num, title, size=(10, 10)):\n",
    "    fig, axs = plt.subplots(h_num, v_num, figsize=size)\n",
    "    shape = data.shape\n",
    "    data = data.reshape(shape[0]*shape[1], shape[2], shape[3])\n",
    "    for idx, ax in enumerate(axs.flatten()):\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if idx < len(data):\n",
    "            ax.imshow(data[idx,:,:], cmap='gray')\n",
    "    plt.suptitle(title)\n",
    "    #plt.tight_layout(rect=[0, 0, 1, 0.97], h_pad=0, w_pad=0)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "# fig0 = plot_nchw_data(c0, 4, 4, 'conv0')\n",
    "print(c0.shape)\n",
    "print(c1.shape)\n",
    "print(c2.shape)\n",
    "\n",
    "fig0 = plot_nchw_data(c0, 1, 4, 'conv0', size=(8,2))\n",
    "\n",
    "fig1 = plot_nchw_data(c1, 4, 4, 'conv1', size=(5,5)) \n",
    "\n",
    "fig2 = plot_nchw_data(c2, 8, 8, 'conv2', size=(10,10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StopLineEstimator(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Conv2d(4, 4, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(4, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "  )\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (lin): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT TO ONNX MODEL FOR OPENCV\n",
    "stop_line_estimator.load_state_dict(torch.load(model_name))\n",
    "\n",
    "#save the model so that opencv can load it\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "device = torch.device('cpu')\n",
    "stop_line_estimator.to(device)\n",
    "\n",
    "# set the model to inference mode\n",
    "stop_line_estimator.eval()\n",
    "\n",
    "# Create some sample input in the shape this model expects \n",
    "# This is needed because the convertion forward pass the network once \n",
    "dummy_input = torch.randn(1, num_channels, SIZE[1], SIZE[0])\n",
    "torch.onnx.export(stop_line_estimator, dummy_input, onnx_model_path, verbose=True)\n",
    "\n",
    "clear_output(wait=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "stop_line_estimator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 4902.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[0.11234414]]\n",
      "Predictions shape: (1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST WITH OPENCV\n",
    "sample_image = \"training_imgs/img_1.png\"\n",
    "images = [cv.imread(f\"training_imgs/img_{i+1}.png\") for i in range(100)]\n",
    " \n",
    "#The Magic:\n",
    "lk =  cv.dnn.readNetFromONNX(onnx_model_path)\n",
    "\n",
    "avg_col = (0,0,0) if num_channels == 3 else 0\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    image = images[i]\n",
    "    image = cv.resize(image, SIZE)\n",
    "    if num_channels == 1:\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    blob = cv.dnn.blobFromImage(image, 1.0, SIZE, avg_col, swapRB=True, crop=False)\n",
    "    # print(blob.shape)\n",
    "    lk.setInput(blob)\n",
    "    preds = lk.forward()\n",
    "    # print(f\"Predictions: {preds[0][2]}\")\n",
    "\n",
    "print(f\"Predictions: {preds}\")\n",
    "print(f\"Predictions shape: {preds.shape}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cee89b7c6bc96453738565335b56b694d8a30ac65e979633b683f8408c8233c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('dl_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
