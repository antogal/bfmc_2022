{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px # this is another plotting library for interactive plot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, manifold # we will use the metrics and manifold learning modules from scikit-learn\n",
    "from pathlib import Path # to interact with file paths\n",
    "from PIL import Image # to interact with images\n",
    "from tqdm import tqdm # progress bar\n",
    "from pprint import pprint # pretty print (useful for a more readable print of objects like lists or dictionaries)\n",
    "from IPython.display import clear_output # to clear the output of the notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2 as cv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Net and create Detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True) #faster but less accurate\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True) \n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5n6', pretrained=True) \n",
    "# model = torch.hub.load('ultralytics/yolov3', 'yolov3') #bad \n",
    "model.to(device)\n",
    "\n",
    "#https://github.com/ultralytics/yolov5/issues/1314\n",
    "\n",
    "#backnbone is layers 0->9\n",
    "\n",
    "backbone_layers = [f'model.{x}' for x in range(10)]\n",
    "\n",
    "backbone = nn.Sequential(\n",
    "    model.model.model.model[0],\n",
    "    model.model.model.model[1],\n",
    "    model.model.model.model[2],\n",
    "    model.model.model.model[3],\n",
    "    model.model.model.model[4],\n",
    "    model.model.model.model[5],\n",
    "    model.model.model.model[6],\n",
    "    model.model.model.model[7],\n",
    "    model.model.model.model[8],\n",
    "    model.model.model.model[9],\n",
    "    model.model.model.model[10],\n",
    "    )\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, backbone): \n",
    "        super().__init__()\n",
    "\n",
    "        ## Pretrained layers\n",
    "        self.pretrained = backbone\n",
    "\n",
    "        #Pool layer\n",
    "        self.pool = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutions\n",
    "        x = self.pretrained(x)\n",
    "        # pool \n",
    "        x = self.pool(x)\n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "        return x\n",
    "\n",
    "class Detector(nn.Module):\n",
    "    def __init__(self, add_inputs=4, regr_out=22, class_out=13, features=76800): #(default for 640x320)\n",
    "        super().__init__()\n",
    "        ### Linear sections\n",
    "        self.lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=features+add_inputs, out_features=1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(in_features=1024, out_features=regr_out+class_out),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "#define Feature Extractor\n",
    "feature_extractor = FeatureExtractor(backbone)\n",
    "#define detector\n",
    "detector = Detector(add_inputs=4, regr_out=8, class_out=15, features=3072) #v1=20480 v2=3072\n",
    "\n",
    "#freeeze backbone\n",
    "for param in feature_extractor.pretrained.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "feature_extractor.to(device)\n",
    "detector.to(device)\n",
    "\n",
    "# #check\n",
    "# for param_name, param in detector.named_parameters():\n",
    "#     print('%s \\t- requires_grad=%s' % (param_name, param.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test backbone\n",
    "#show the image with opencv\n",
    "img = cv.imread('tests/test_img.jpg')\n",
    "#resize to 480 x 640\n",
    "img = cv.resize(img, (320, 240))\n",
    "#convert to tensor\n",
    "img = torch.from_numpy(img).float().permute(2, 0, 1)\n",
    "#add dimension\n",
    "img = img.unsqueeze(0).to(device)\n",
    "print(img.shape)\n",
    "\n",
    "detector.eval()\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    data = torch.zeros(1, 4).to(device)\n",
    "    feat = feature_extractor(img)\n",
    "    print(f'feat shape: {feat.shape}')\n",
    "    input = torch.cat((feat, data), dim=1)\n",
    "    print(f'input shape: {input.shape}')\n",
    "    out = detector(input) \n",
    "    print(f'out shape: {out.shape}') # (320, 240)->torch.Size([1, 20480]) v2-> torch.Size([1, 3076])\n",
    "                    # (640, 480)->torch.Size([1, 76800])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #augmentation tests\n",
    "# import cv2 as cv\n",
    "# import numpy as np\n",
    "\n",
    "# idx=0\n",
    "# img = cv.imread(f'training/img_{idx+1}.png')\n",
    "# #add noise with cv2\n",
    "# std = 3\n",
    "# noisep = np.random.normal(0, std, img.shape)\n",
    "# noisep = np.uint8(noisep)\n",
    "# noisem = np.random.normal(0, std, img.shape)\n",
    "# noisem = np.uint8(noisem)\n",
    "# img = cv.subtract(img, noisem)\n",
    "# img = cv.add(img, noisep)\n",
    "# img = cv.blur(img, (3,3))\n",
    "# img = cv.resize(img, (320, 240))\n",
    "# cv.imshow('img', img)\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "class AuxImgDataset(Dataset):\n",
    "    def __init__(self, folder, feature_extractor, num_images):\n",
    "        self.folder = folder\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.num_images = num_images\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = read_image(os.path.join(self.folder, f'img_{idx+1}.png') )\n",
    "        #convert to tensor\n",
    "        img = img.float()\n",
    "        return img\n",
    "\n",
    "def analyze_class_labels(class_labels):\n",
    "    state_cnt = [0,0,0,0]\n",
    "    next_state_cnt = [0,0,0,0]\n",
    "    sign_cnt = [0,0,0,0,0,0,0]\n",
    "    for label in tqdm(class_labels):\n",
    "        #torch->numpy\n",
    "        label = label.numpy()\n",
    "        assert np.sum(label) == 3, f'{label}'\n",
    "        state_lab = label[0:4]\n",
    "        assert np.sum(state_lab) == 1, f'{state_lab}'\n",
    "        state_cnt[np.argmax(state_lab)] += 1\n",
    "        next_state_lab = label[4:8]\n",
    "        assert np.sum(next_state_lab) == 1, f'{next_state_lab}'\n",
    "        next_state_cnt[np.argmax(next_state_lab)] += 1\n",
    "        sign_lab = label[8:15]\n",
    "        assert np.sum(sign_lab) == 1, f'{sign_lab}'\n",
    "        sign_cnt[np.argmax(sign_lab)] += 1\n",
    "    print(f'State counts: {state_cnt}   , tot = {np.sum(state_cnt)}')\n",
    "    print(f'Road :        {state_cnt[0]},  {state_cnt[0]/np.sum(state_cnt):.2f}') \n",
    "    print(f'Intersection: {state_cnt[1]},  {state_cnt[1]/np.sum(state_cnt):.2f}')\n",
    "    print(f'Roundabout:   {state_cnt[2]},  {state_cnt[2]/np.sum(state_cnt):.2f}')\n",
    "    print(f'Junction:     {state_cnt[3]},  {state_cnt[3]/np.sum(state_cnt):.2f}')\n",
    "    print(f'Next state counts: {next_state_cnt}')\n",
    "    print(f'Next Road :        {next_state_cnt[0]},  {next_state_cnt[0]/np.sum(next_state_cnt):.2f}')\n",
    "    print(f'Next Intersection: {next_state_cnt[1]},  {next_state_cnt[1]/np.sum(next_state_cnt):.2f}')\n",
    "    print(f'Next Roundabout:   {next_state_cnt[2]},  {next_state_cnt[2]/np.sum(next_state_cnt):.2f}')\n",
    "    print(f'Next Junction:     {next_state_cnt[3]},  {next_state_cnt[3]/np.sum(next_state_cnt):.2f}')\n",
    "    print(f'Sign counts: {sign_cnt}')\n",
    "\n",
    "    return state_cnt, next_state_cnt, sign_cnt\n",
    "\n",
    "def analyze_additional_inputs(additional_inputs):\n",
    "    action_cnt = [0,0,0,0]\n",
    "    for input in tqdm(additional_inputs):\n",
    "        input = input.numpy()\n",
    "        assert np.sum(input) == 1, f'{input}'\n",
    "        action_lab = input[0:4]\n",
    "        assert np.sum(action_lab) == 1, f'{action_lab}'\n",
    "        action_cnt[np.argmax(action_lab)] += 1\n",
    "    print(f'Action counts: {action_cnt},  tot = {np.sum(action_cnt)}')\n",
    "    print(f'Straight:    {action_cnt[0]},  {action_cnt[0]/np.sum(action_cnt):.2f}')\n",
    "    print(f'Left:        {action_cnt[1]},  {action_cnt[1]/np.sum(action_cnt):.2f}')\n",
    "    print(f'Right:       {action_cnt[2]},  {action_cnt[2]/np.sum(action_cnt):.2f}')\n",
    "    print(f'Continue:    {action_cnt[3]},  {action_cnt[3]/np.sum(action_cnt):.2f}')\n",
    "\n",
    "    return action_cnt\n",
    "\n",
    "\n",
    "class CsvDataset(Dataset):\n",
    "    def __init__(self, folder, feature_extractor, transform=None, max_load=1000, num_images=5000, equalize=False, skip_img_load=False):\n",
    "        self.transform = transform\n",
    "        self.folder = folder\n",
    "        self.data = []\n",
    "        self.tot_imgs = num_images\n",
    "\n",
    "        #classification labels\n",
    "        class_labels = []\n",
    "        with open(folder+'/classification_labels.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            # #set maximumum number of images\n",
    "            self.max_load = min(max_load, len(lines))\n",
    "            for i in tqdm(range(self.max_load)):\n",
    "                line = lines[i]\n",
    "                sample = line.split(',')\n",
    "                #convert to float\n",
    "                label = np.array([float(s) for s in sample])\n",
    "                #convert to tensor\n",
    "                label = torch.from_numpy(label).float()\n",
    "                class_labels.append(label)\n",
    "        \n",
    "        \n",
    "        #input data\n",
    "        input_data = []\n",
    "        with open(folder+'/input_data.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            for i in tqdm(range(self.max_load)):\n",
    "                line = lines[i]\n",
    "                sample = line.split(',')\n",
    "                label = np.array([float(s) for s in sample])\n",
    "                label = torch.from_numpy(label).float()\n",
    "                input_data.append(label)\n",
    "\n",
    "\n",
    "         #regression labels\n",
    "        regr_labels = []\n",
    "        with open(folder+'/regression_labels.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            for i in tqdm(range(self.max_load)):\n",
    "                line = lines[i]\n",
    "                sample = line.split(',')\n",
    "                reg_label = np.array([float(s) for s in sample])\n",
    "                reg_label = torch.from_numpy(reg_label).float()\n",
    "                regr_labels.append(reg_label)\n",
    "\n",
    "        if not skip_img_load:\n",
    "            #add noise to images\n",
    "            #clear the training folder\n",
    "            train_folder = 'training'\n",
    "            for file in os.listdir(train_folder):\n",
    "                if file.endswith(\".png\"):\n",
    "                    os.remove(os.path.join(train_folder, file))\n",
    "            for i in tqdm(range(self.max_load)):\n",
    "                img = cv.imread(self.folder+f'/img_{i+1}.png')\n",
    "                #add noise \n",
    "                std = 3\n",
    "                noisep = np.random.normal(0, std, img.shape)\n",
    "                noisep = np.uint8(noisep)\n",
    "                noisem = np.random.normal(0, std, img.shape)\n",
    "                noisem = np.uint8(noisem)\n",
    "                img = cv.subtract(img, noisem)\n",
    "                img = cv.add(img, noisep)\n",
    "                if np.random.uniform(0, 1) > 0.7:\n",
    "                    img = cv.blur(img, (5,5))\n",
    "                img = cv.resize(img, (320, 240))\n",
    "                cv.imwrite(train_folder+f'/img_{i+1}.png', img)\n",
    "\n",
    "        if equalize:\n",
    "            print('Before Equalization: ')\n",
    "            state_cnt, next_cnt, sign_cnt = analyze_class_labels(class_labels) #print useful info about the labels\n",
    "            action_cnt = analyze_additional_inputs(input_data) #print useful info about the inputs\n",
    "            \n",
    "            #Equalize the number of samples per class\n",
    "            # state_multipliers = [1.0,1.0,1.0,1.0] #to equalize the number of samples per class\n",
    "            next_multipliers = [1.0,1.0,1.0,1.0] #to equalize the number of samples per class\n",
    "            # max_state = np.max(state_cnt)\n",
    "            max_next = np.max(next_cnt)\n",
    "            # for i in range(len(state_cnt)):\n",
    "            #     if state_cnt[i] > 1e-4:\n",
    "            #         state_multipliers[i] = max_state/state_cnt[i]\n",
    "            for i in range(len(next_cnt)):\n",
    "                if next_cnt[i] > 1e-4:\n",
    "                    next_multipliers[i] = max_next/next_cnt[i]\n",
    "            new_next_samples = [int(next_multipliers[i]*next_cnt[i]) for i in range(len(state_cnt))]\n",
    "            print(f'new_next_samples: {new_next_samples}, tot = {np.sum(new_next_samples)}')\n",
    "\n",
    "            tot_samples = np.sum(new_next_samples)\n",
    "\n",
    "            #create the new samples\n",
    "            final_class_labels = []\n",
    "            final_input_data = []\n",
    "            final_regr_labels = []\n",
    "            finished = False\n",
    "            idx = 0\n",
    "            final_idx = 0\n",
    "            # state_cnt = [0,0,0,0] \n",
    "            next_cnt = [0,0,0,0] #equalize only on this\n",
    "            while not all([next_cnt[i] >= new_next_samples[i] for i in range(len(next_cnt))]):\n",
    "                #get the next state\n",
    "                next = class_labels[idx][4:8]\n",
    "                assert np.sum(next.numpy()) == 1, f'{next}'\n",
    "                assert next.shape == (4,)\n",
    "                next_idx = np.argmax(next)\n",
    "                next_cnt[next_idx] += 1\n",
    "                if next_cnt[next_idx] < new_next_samples[next_idx]:\n",
    "                    final_class_labels.append(class_labels[idx])\n",
    "                    final_input_data.append(input_data[idx])\n",
    "                    final_regr_labels.append(regr_labels[idx])\n",
    "                    shutil.copyfile(self.folder+f'/img_{idx+1}.png', f'training/img_{final_idx+1}.png')\n",
    "                    final_idx += 1\n",
    "\n",
    "                idx = (idx+1) % len(class_labels) #increment index\n",
    "                if idx % 50000 == 0:\n",
    "                    print(f'{idx}, {final_idx}')\n",
    "\n",
    "            print('After Equalization: ')\n",
    "            analyze_class_labels(final_class_labels) #print useful info about the labels\n",
    "            analyze_additional_inputs(final_input_data) #print useful info about the inputs\n",
    "\n",
    "            print(f'Final idx = {final_idx}')\n",
    "            tot_samples = final_idx\n",
    "            img_folder = 'training'\n",
    "        else:\n",
    "            img_folder = 'training'\n",
    "            tot_samples = min(self.max_load, len(class_labels))\n",
    "            final_class_labels = class_labels\n",
    "            final_input_data = input_data\n",
    "            final_regr_labels = regr_labels\n",
    "\n",
    "        #convert images into features\n",
    "        #imgs dataset\n",
    "        img_dataset = AuxImgDataset(img_folder, feature_extractor, tot_samples)\n",
    "        img_loader = DataLoader(img_dataset, batch_size=128, shuffle=False)\n",
    "        feature_extractor.eval()\n",
    "        features = []\n",
    "        with torch.no_grad():\n",
    "            for imgs in tqdm(img_loader):\n",
    "                imgs = imgs.to(device)\n",
    "                feat = feature_extractor(imgs)\n",
    "                feat = feat.cpu()\n",
    "                for j in range(feat.shape[0]):\n",
    "                    features.append(feat[j])\n",
    "        \n",
    "        #add everything to self.data\n",
    "        for i in tqdm(range(tot_samples)):\n",
    "            #concatenate feature vector and additional input data (input for the linear layer)\n",
    "            input = torch.cat((features[i], final_input_data[i]), dim=0)\n",
    "            # print(f'input shape: {input.shape}')\n",
    "            #append to data\n",
    "            self.data.append((input, final_regr_labels[i], final_class_labels[i]))  \n",
    "\n",
    "    def __len__(self):\n",
    "        # The length of the dataset is simply the length of the self.data list\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Our sample is the element idx of the list self.data\n",
    "        sample = self.data[idx]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CsvDataset(Dataset):\n",
    "#     def __init__(self, folder, feature_extractor, transform=None):\n",
    "#         self.transform = transform\n",
    "#         self.folder = folder\n",
    "#         self.data = []\n",
    "#         class_labels = []\n",
    "#         with open(folder+'/classification_labels.csv', 'r') as f:\n",
    "#             lines = f.read().split('\\n')\n",
    "#             lines = lines[0:-1] #remove footer\n",
    "#             # Get x and y values from each line and append to self.data\n",
    "#             labels = []\n",
    "#             for i in tqdm(range(len(lines))):\n",
    "#                 line = lines[i]\n",
    "#                 sample = line.split(',')\n",
    "#                 #convert to float\n",
    "#                 label = np.array([float(s) for s in sample])\n",
    "#                 #convert to tensor\n",
    "#                 label = torch.from_numpy(label).float()\n",
    "#                 # img = img.unsqueeze(0)\n",
    "#                 class_labels.append(label)\n",
    "\n",
    "#         input_data = []\n",
    "#         with open(folder+'/input_data.csv', 'r') as f:\n",
    "#             lines = f.read().split('\\n')\n",
    "#             lines = lines[0:-1] #remove footer\n",
    "#             # Get x and y values from each line and append to self.data\n",
    "#             labels = []\n",
    "#             for i in tqdm(range(len(lines))):\n",
    "#                 line = lines[i]\n",
    "#                 sample = line.split(',')\n",
    "#                 #convert to float\n",
    "#                 label = np.array([float(s) for s in sample])\n",
    "#                 #convert to tensor\n",
    "#                 label = torch.from_numpy(label).float()\n",
    "#                 # img = img.unsqueeze(0)\n",
    "#                 input_data.append(label)\n",
    "\n",
    "#         #load labels and convert images in features\n",
    "#         feature_extractor.eval()\n",
    "\n",
    "#         with open(folder+'/regression_labels.csv', 'r') as f:\n",
    "#             lines = f.read().split('\\n')\n",
    "#             lines = lines[0:-1] #remove footer\n",
    "#             # Get x and y values from each line and append to self.data\n",
    "#             labels = []\n",
    "#             for i in tqdm(range(len(lines))):\n",
    "#                 line = lines[i]\n",
    "#                 sample = line.split(',')\n",
    "#                 #convert to float\n",
    "#                 reg_label = np.array([float(s) for s in sample])\n",
    "#                 #convert to tensor\n",
    "#                 reg_label = torch.from_numpy(reg_label).float()\n",
    "#                 img = cv.imread(folder+f'/img_{i+1}.png')\n",
    "#                 img = cv.resize(img, (320, 240))\n",
    "#                 img = torch.from_numpy(img).float().permute(2, 0, 1)\n",
    "#                 img = img.unsqueeze(0).to(device)\n",
    "#                 #create feature vector \n",
    "#                 feat = feature_extractor(img)\n",
    "#                 # print(f'feat shape: {feat.shape}')\n",
    "#                 feat = feat[0].cpu()\n",
    "#                 #concatenate feature vector and additional input data (input for the linear layer)\n",
    "#                 input = torch.cat((feat, input_data[i]), dim=0)\n",
    "#                 # print(f'input shape: {input.shape}')\n",
    "#                 #append to data\n",
    "#                 self.data.append((input, reg_label, class_labels[i]))  \n",
    "\n",
    "#     def __len__(self):\n",
    "#         # The length of the dataset is simply the length of the self.data list\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         # Our sample is the element idx of the list self.data\n",
    "#         sample = self.data[idx]\n",
    "#         return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset #takes a long time but then training is faster\n",
    "train_dataset = CsvDataset('training_imgs', feature_extractor,max_load=10000, num_images=200000, equalize=False, skip_img_load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test dataloader\n",
    "sample = next(iter(train_dataloader))\n",
    "print(sample[0].shape)\n",
    "print(sample[1].shape)\n",
    "print(sample[2].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(det, dataloader, class_loss_fn, regr_loss_fn, optimizer, device=device):\n",
    "    # Set the model to training mode\n",
    "    # ext.eval() #dont train the extractor\n",
    "    det.train() #train detector\n",
    "    # Initialize the loss\n",
    "    train_loss_class = []\n",
    "    train_loss_regr = []\n",
    "\n",
    "    err_losses = []\n",
    "    dist_losses = []\n",
    "    curv_losses = []\n",
    "    bb_losses = []\n",
    "\n",
    "    # Loop over the training batches\n",
    "    for (input, regr_label, class_label) in tqdm(dataloader):\n",
    "        # Move the input and target data to the selected device\n",
    "        input, regr_label, class_label =input.to(device), regr_label.to(device), class_label.to(device)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the output\n",
    "        output = det(input)\n",
    "\n",
    "        #regression 22 values\n",
    "        #classification: 3 states, 3 next states, 7 signs\n",
    "        regr_out = output[:, 0:8]\n",
    "        err_out = regr_out[:, 0:2]\n",
    "        dist_out = regr_out[:, 2]\n",
    "        curv_out = regr_out[:, 3]\n",
    "        bb_out = regr_out[:, 4:8]\n",
    "\n",
    "        err_label = regr_label[:, 0:2]\n",
    "        dist_label = regr_label[:, 2]\n",
    "        dist_label = torch.where(dist_label < 0.8, dist_label, dist_out) #consider loss only for small distances\n",
    "        curv_label = regr_label[:, 3]\n",
    "        bb_label = regr_label[:, 4:8]\n",
    "\n",
    "        #classification\n",
    "        class_out = output[:, 8:23]\n",
    "        state_out = class_out[:, 0:4]\n",
    "        next_out = class_out[:, 4:8]\n",
    "        sign_out = class_out[:, 8:15]\n",
    "        \n",
    "        state_label = class_label[:, 0:4]\n",
    "        next_label = class_label[:, 4:8]\n",
    "        sign_label = class_label[:, 8:15]\n",
    "\n",
    "        # Compute the losses\n",
    "        err_loss = 50.0*regr_loss_fn(err_out, err_label)\n",
    "        dist_loss = 0.1*regr_loss_fn(dist_out, dist_label) \n",
    "        curv_loss = 0.1*regr_loss_fn(curv_out, curv_label)\n",
    "        bb_loss = 0.0*regr_loss_fn(bb_out, bb_label)\n",
    "\n",
    "        state_loss = 0.0*class_loss_fn(state_out, state_label)\n",
    "        next_loss = 0.0*class_loss_fn(next_out, next_label)\n",
    "        assert sign_out.shape == sign_label.shape, f'{sign_out.shape} != {sign_label.shape}'\n",
    "        sign_loss = 0.0*class_loss_fn(sign_out, sign_label)\n",
    "        loss = err_loss + dist_loss + curv_loss + bb_loss + state_loss + next_loss + sign_loss\n",
    "\n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #batch loss\n",
    "        c_loss = (state_loss + next_loss + sign_loss).detach().cpu().numpy()\n",
    "        train_loss_class.append(c_loss)\n",
    "        err_losses.append(err_loss.detach().cpu().numpy())\n",
    "        dist_losses.append(dist_loss.detach().cpu().numpy())\n",
    "        curv_losses.append(curv_loss.detach().cpu().numpy())\n",
    "        bb_losses.append(bb_loss.detach().cpu().numpy())\n",
    "\n",
    "    # Return the average training loss\n",
    "    train_loss_c = np.mean(train_loss_class)\n",
    "    err_loss = np.mean(err_losses)\n",
    "    dist_loss = np.mean(dist_losses)\n",
    "    curv_loss = np.mean(curv_losses)\n",
    "    bb_loss = np.mean(bb_losses)\n",
    "    return train_loss_c, err_loss, dist_loss, curv_loss, bb_loss\n",
    "\n",
    "def get_avg_loss(ext, det, dataloader, class_loss_fn, regr_loss_fn, device):\n",
    "    ext.eval()\n",
    "    det.eval()\n",
    "    class_losses = []\n",
    "    regr_losses = []\n",
    "    with torch.no_grad():\n",
    "        for (input, regr_label, class_label) in tqdm(dataloader):\n",
    "            # Move the input and target data to the selected device\n",
    "            input, regr_label, class_label =input.to(device), regr_label.to(device), class_label.to(device)\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Compute the output\n",
    "            output = det(input)\n",
    "            \n",
    "            #regression 22 values\n",
    "            #classification: 4 states, 4 next states, 7 signs\n",
    "            regr_out = output[:, :22]\n",
    "            state_out = output[:, 22:25]\n",
    "            next_out = output[:, 25:28]\n",
    "            sign_out = output[:, 28:]\n",
    "            \n",
    "            state_label = class_label[:, 0:3]\n",
    "            next_label = class_label[:, 3:6]\n",
    "            sign_label = class_label[:, 6:]\n",
    "\n",
    "            # Compute the losses\n",
    "            regr_loss = regr_loss_fn(regr_out, regr_label)\n",
    "            state_loss = class_loss_fn(state_out, state_label)\n",
    "            next_loss = class_loss_fn(next_out, next_label)\n",
    "            sign_loss = class_loss_fn(sign_out, sign_label)\n",
    "            class_loss = state_loss + next_loss + sign_loss\n",
    "\n",
    "            class_losses.append(class_loss.detach().cpu().numpy())\n",
    "            regr_losses.append(regr_loss.detach().cpu().numpy())\n",
    "    # Return the accuracy and test loss\n",
    "    class_loss = np.mean(class_losses)\n",
    "    regr_loss = np.mean(regr_losses)\n",
    "    return class_loss, regr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load models\n",
    "# detector.load_state_dict(torch.load('detector.pt'))\n",
    "# feature_extractor.load_state_dict(torch.load('feature_extractor.pt'))\n",
    "\n",
    "#parameters\n",
    "lr = 0.001\n",
    "epochs = 150\n",
    "optimizer = torch.optim.Adam(detector.parameters(), lr=lr, weight_decay=0.0)\n",
    "regr_loss_fn = nn.MSELoss()\n",
    "class_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # try:\n",
    "    if True:\n",
    "        train_loss_c, err_loss, dist_loss, curv_loss, bb_loss = train_epoch(detector, train_dataloader, class_loss_fn, regr_loss_fn, optimizer, device)\n",
    "        clear_output(wait=True)\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    #     torch.cuda.empty_cache()\n",
    "    #     continue\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"err_loss: {err_loss}\")\n",
    "    print(f\"dist_loss: {dist_loss}\")\n",
    "    print(f\"curv_loss: {curv_loss}\")\n",
    "    print(f\"bb_loss: {bb_loss}\")\n",
    "    print(f\"Classification loss: {train_loss_c}\")\n",
    "    torch.save(detector.state_dict(), 'models/detector.pt')\n",
    "    torch.save(feature_extractor.state_dict(), 'models/feature_extractor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing\n",
    "# test_dataset = CsvDataset(folder='test_imgs')\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "# #get accuracy\n",
    "# train_class_loss, train_regr_loss = get_avg_loss(feature_extractor, detector, train_dataloader, class_loss_fn, regr_loss_fn, device)\n",
    "# test_class_loss, test_regr_loss = get_avg_loss(feature_extractor, detector, test_dataloader, class_loss_fn, regr_loss_fn, device)\n",
    "\n",
    "# print(f\"Training classification loss: {train_class_loss}\")\n",
    "# print(f\"Training regression loss: {train_regr_loss}\\n\")\n",
    "# print(f\"Testing classification loss: {test_class_loss}\")\n",
    "# print(f\"Testing regression loss: {test_regr_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.load_state_dict(torch.load('models/detector.pt'))\n",
    "feature_extractor.load_state_dict(torch.load('models/feature_extractor.pt'))\n",
    "\n",
    "# #save pytorch model\n",
    "# torch.save(detector.state_dict(), 'detector.pt')\n",
    "# torch.save(feature_extractor.state_dict(), 'feature_extractor.pt')\n",
    "\n",
    "#save the model so that opencv can load it\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "device = torch.device('cpu')\n",
    "detector.to(device)\n",
    "feature_extractor.to(device)\n",
    " \n",
    "onnx_detector_path = \"models/detector.onnx\"\n",
    "onnx_feature_extractor_path = \"models/feature_extractor.onnx\"\n",
    "\n",
    "# set the model to inference mode\n",
    "detector.eval()\n",
    "feature_extractor.eval()\n",
    " \n",
    "# Create some sample input in the shape this model expects \n",
    "# This is needed because the convertion forward pass the network once \n",
    "dummy_input = torch.randn(1, 3, 240, 320)\n",
    "dummy_input2 = torch.randn(1, 3076) \n",
    "torch.onnx.export(feature_extractor, dummy_input, onnx_feature_extractor_path, verbose=True)\n",
    "torch.onnx.export(detector, dummy_input2, onnx_detector_path, verbose=True)\n",
    "\n",
    "clear_output(wait=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test with opencv\n",
    "sample_image = \"training_imgs/img_1.png\"\n",
    "images = [cv.imread(f\"training_imgs/img_{i+1}.png\") for i in range(100)]\n",
    " \n",
    "#The Magic:\n",
    "det =  cv.dnn.readNetFromONNX(onnx_detector_path) \n",
    "ext = cv.dnn.readNetFromONNX(onnx_feature_extractor_path)\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    image = images[i]\n",
    "    blob = cv.dnn.blobFromImage(image, 1.0, (320, 240),(0, 0, 0), swapRB=True, crop=False)\n",
    "    ext.setInput(blob)\n",
    "    features = ext.forward()\n",
    "    # print(features.shape)\n",
    "    action_vec = np.ones((1,4))\n",
    "    input = np.concatenate((features, action_vec), axis=1)\n",
    "    # print(input.shape)\n",
    "    det.setInput(input)\n",
    "    preds = det.forward()\n",
    "\n",
    "print(f\"Predictions: {preds}\")\n",
    "print(f\"Predictions shape: {preds.shape}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cee89b7c6bc96453738565335b56b694d8a30ac65e979633b683f8408c8233c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('dl_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
