{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px # this is another plotting library for interactive plot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, manifold # we will use the metrics and manifold learning modules from scikit-learn\n",
    "from pathlib import Path # to interact with file paths\n",
    "from PIL import Image # to interact with images\n",
    "from tqdm import tqdm # progress bar\n",
    "from pprint import pprint # pretty print (useful for a more readable print of objects like lists or dictionaries)\n",
    "from IPython.display import clear_output # to clear the output of the notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2 as cv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTROL\n",
    "num_channels = 1\n",
    "SIZE = (128,64)\n",
    "model_name = 'models/lane_keeper_small.pt'\n",
    "onnx_lane_keeper_path = \"models/lane_keeper_small.onnx\"\n",
    "max_load = 150_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Net and create Detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "\n",
    "class LaneKeeper(nn.Module):\n",
    "    def __init__(self, out_dim=4, channels=1): \n",
    "        super().__init__()\n",
    "        ### Convoluational layers\n",
    "        self.conv = nn.Sequential( #in = (SIZE)\n",
    "            nn.Conv2d(channels, 32, kernel_size=5, stride=2), #out = (62,30)\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, kernel_size=7, stride=2), #out = (28,12)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1), #out = (27,11)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=5, stride=2), #out = (12,4)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),#out = (6,2)\n",
    "        )\n",
    "        self.flat = nn.Flatten()\n",
    "        ### Linear sections\n",
    "        self.lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=6*2*64, out_features=256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(in_features=256, out_features=out_dim),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "lane_keeper = LaneKeeper(out_dim=4,channels=num_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64, 128])\n",
      "out shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#show the image with opencv\n",
    "img = cv.imread('tests/test_img.jpg')\n",
    "img = cv.resize(img, SIZE)\n",
    "if num_channels == 1:\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "#convert to tensor\n",
    "img = torch.from_numpy(img).float()\n",
    "img = img.permute(2,0,1)\n",
    "#add dimension\n",
    "img = img.unsqueeze(0).to(device)\n",
    "print(img.shape)\n",
    "\n",
    "lane_keeper.eval()\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    output = lane_keeper(img)\n",
    "    print(f'out shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def load_and_augment_img(i, folder='training_imgs'):\n",
    "    img = cv.imread(os.path.join(folder, f'img_{i+1}.png'))\n",
    "\n",
    "    #convert to gray\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    #create random ellipses to simulate light from the sun\n",
    "    light = np.zeros(img.shape, dtype=np.uint8)\n",
    "    #add ellipses\n",
    "    for j in range(2):\n",
    "        cent = (np.random.randint(0, img.shape[0]), np.random.randint(0, img.shape[1]))\n",
    "        axes_length = (np.random.randint(10, 50), np.random.randint(50, 300))\n",
    "        angle = np.random.randint(0, 360)\n",
    "        light = cv.ellipse(light, cent, axes_length, angle, 0, 360, 255, -1)\n",
    "    #create an image of random white and black pixels\n",
    "    light = cv.blur(light, (100,100))\n",
    "    noise = np.random.randint(0, 2, size=img.shape, dtype=np.uint8)*255\n",
    "    light = cv.subtract(light, noise)\n",
    "    light = 5 * light\n",
    "\n",
    "    #add light to the image\n",
    "    img = cv.add(img, light)\n",
    "\n",
    "    # cv.imshow('light', light)\n",
    "    # if cv.waitKey(0) == ord('q'):\n",
    "    #     break\n",
    "\n",
    "    # cut the top third of the image, let it 640x320\n",
    "    img = img[int(img.shape[0]/3):,:]\n",
    "    assert img.shape == (320,640), f'img shape cut = {img.shape}'\n",
    "    #resize \n",
    "    img = cv.resize(img, SIZE)\n",
    "\n",
    "    #add random tilt\n",
    "    max_offset = 5\n",
    "    offset = np.random.randint(-max_offset, max_offset)\n",
    "    img = np.roll(img, offset, axis=0)\n",
    "    if offset > 0:\n",
    "        img[:offset, :] = np.random.randint(0,255)\n",
    "    elif offset < 0:\n",
    "        img[offset:, :] = np.random.randint(0,255)\n",
    "\n",
    "    #reduce contrast\n",
    "    const = np.random.uniform(0.1,1.2)\n",
    "    if np.random.uniform() > 5:\n",
    "        const = const*0.2\n",
    "    img = 127*(1-const) + img*const\n",
    "    img = img.astype(np.uint8)\n",
    "\n",
    "    #add noise \n",
    "    std = 150\n",
    "    std = np.random.randint(1, std)\n",
    "    noisem = np.random.randint(0, std, img.shape, dtype=np.uint8)\n",
    "    img = cv.subtract(img, noisem)\n",
    "    noisep = np.random.randint(0, std, img.shape, dtype=np.uint8)\n",
    "    img = cv.add(img, noisep)\n",
    "    #blur \n",
    "    img = cv.blur(img, (5,5))\n",
    "\n",
    "    #add random brightness\n",
    "    max_brightness = 50\n",
    "    brightness = np.random.randint(-max_brightness, max_brightness)\n",
    "    if brightness > 0:\n",
    "        img = cv.add(img, brightness)\n",
    "    elif brightness < 0:\n",
    "        img = cv.subtract(img, -brightness)\n",
    "    \n",
    "    # invert color\n",
    "    if np.random.uniform(0, 1) > 0.6:\n",
    "        img = cv.bitwise_not(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "cv.namedWindow('img', cv.WINDOW_NORMAL)\n",
    "cv.setWindowProperty('img', cv.WND_PROP_FULLSCREEN, cv.WINDOW_FULLSCREEN)\n",
    "\n",
    "for i in range(500):\n",
    "    img = load_and_augment_img(i)\n",
    "    cv.imshow('img', img)\n",
    "    key = cv.waitKey(1)\n",
    "    if key == ord('q') or key == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None, max_load=1000, channels=3):\n",
    "        self.transform = transform\n",
    "        self.folder = folder\n",
    "        self.data = []\n",
    "        self.channels = channels\n",
    "    \n",
    "        with open(folder+'/regression_labels.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            # Get x and y values from each line and append to self.data\n",
    "            max_load = min(max_load, len(lines))\n",
    "            self.all_imgs = torch.zeros((max_load, SIZE[1], SIZE[0], channels), dtype=torch.uint8)\n",
    "\n",
    "            labels = []\n",
    "            cv.namedWindow('img', cv.WINDOW_NORMAL)\n",
    "            cv.setWindowProperty('img', cv.WND_PROP_FULLSCREEN, cv.WINDOW_FULLSCREEN)\n",
    "            for i in tqdm(range(max_load)):\n",
    "                #img \n",
    "                img = load_and_augment_img(i)\n",
    "                if i < 1000:\n",
    "                    cv.imshow('img', img)\n",
    "                    cv.waitKey(1)\n",
    "                    if i == 999:\n",
    "                        cv.destroyAllWindows()\n",
    "                \n",
    "                #add a dimension to the image\n",
    "                img = img[:, :,np.newaxis]\n",
    "                self.all_imgs[i] = torch.from_numpy(img)\n",
    "                \n",
    "                #label\n",
    "                line = lines[i]\n",
    "                sample = line.split(',')\n",
    "                reg_label = np.array([float(s) for s in sample], dtype=np.float32)\n",
    "                reg_label = reg_label[0:4] #keep it very simple\n",
    "                self.data.append(reg_label)  \n",
    "\n",
    "    def __len__(self):\n",
    "        # The length of the dataset is simply the length of the self.data list\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # img = read_image(os.path.join(self.folder, f'img_{idx+1}.png'))\n",
    "        # img = img.float()\n",
    "        img = self.all_imgs[idx]\n",
    "        img = img.permute(2, 0, 1).float()\n",
    "        value = self.data[idx]\n",
    "        return img, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142527/142527 [17:26<00:00, 136.15it/s]\n"
     ]
    }
   ],
   "source": [
    "#create dataset #takes a long time but then training is faster\n",
    "train_dataset = CsvDataset('training_imgs', max_load=max_load, channels=num_channels)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 64, 128])\n",
      "torch.Size([100, 4])\n"
     ]
    }
   ],
   "source": [
    "#test dataloader\n",
    "sample = next(iter(train_dataloader))\n",
    "print(sample[0].shape)\n",
    "print(sample[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, dataloader, regr_loss_fn, optimizer, device=device):\n",
    "    # Set the model to training mode\n",
    "    model.train() #train\n",
    "    # Initialize the loss\n",
    "    err_losses3 = []\n",
    "    dist_losses = []\n",
    "    curv_losses = []\n",
    "\n",
    "    # Loop over the training batches\n",
    "    for (input, regr_label) in tqdm(dataloader):\n",
    "        # Move the input and target data to the selected device\n",
    "        input, regr_label =input.to(device), regr_label.to(device)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the output\n",
    "        output = model(input)\n",
    "\n",
    "        #regression\n",
    "        regr_out = output[:, 0:4]\n",
    "        err2 = regr_out[:, 0]\n",
    "        err3 = regr_out[:, 1]\n",
    "        dist_out = regr_out[:, 2]\n",
    "        curv_out = regr_out[:, 3]\n",
    "\n",
    "        err2_label = regr_label[:, 0]\n",
    "        err3_label = regr_label[:, 1]\n",
    "        dist_label = regr_label[:, 2].float()\n",
    "        dist_label = torch.where(dist_label < 0.2, torch.abs(1/(torch.abs(dist_label)+0.1))-10./3, torch.zeros_like(dist_out)).float() #consider loss only for small distances\n",
    "        # print(dist_label)\n",
    "        curv_label = regr_label[:, 3]\n",
    "\n",
    "        # Compute the losses\n",
    "        err_loss3 = 1.0*regr_loss_fn(err3, err3_label)\n",
    "        err_loss2 = .8*regr_loss_fn(err2, err2_label)\n",
    "        dist_loss = .5*regr_loss_fn(dist_out, dist_label) \n",
    "        curv_loss = .5*regr_loss_fn(curv_out, curv_label)\n",
    "        loss = err_loss3 + err_loss2 + dist_loss + curv_loss\n",
    "\n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #batch loss\n",
    "        err_losses3.append(err_loss3.detach().cpu().numpy())\n",
    "        dist_losses.append(dist_loss.detach().cpu().numpy())\n",
    "        curv_losses.append(curv_loss.detach().cpu().numpy())\n",
    "\n",
    "    # Return the average training loss\n",
    "    err_loss3 = np.mean(err_losses3)\n",
    "    dist_loss = np.mean(dist_losses)\n",
    "    curv_loss = np.mean(curv_losses)\n",
    "    return err_loss3, dist_loss, curv_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1426/1426 [02:14<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "err_loss: 0.017495926469564438\n",
      "dist_loss: 0.2149633765220642\n",
      "curv_loss: 0.0003558959870133549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1426/1426 [02:14<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4\n",
      "err_loss: 0.011687005870044231\n",
      "dist_loss: 0.16492792963981628\n",
      "curv_loss: 0.0001309871586272493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1426/1426 [02:14<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4\n",
      "err_loss: 0.010366911068558693\n",
      "dist_loss: 0.14252935349941254\n",
      "curv_loss: 0.00013538022176362574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1426/1426 [02:14<00:00, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4\n",
      "err_loss: 0.009660974144935608\n",
      "dist_loss: 0.12860824167728424\n",
      "curv_loss: 0.00012046621122863144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAINING \n",
    "#parameters\n",
    "lr = 0.001\n",
    "epochs = 4\n",
    "optimizer = torch.optim.Adam(lane_keeper.parameters(), lr=lr, weight_decay=3e-5)\n",
    "regr_loss_fn = nn.MSELoss()\n",
    "for epoch in range(epochs):\n",
    "    # try:\n",
    "    if True:\n",
    "        err_loss, dist_loss, curv_loss = train_epoch(lane_keeper, train_dataloader, regr_loss_fn, optimizer, device)\n",
    "        # clear_output(wait=True)\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    #     torch.cuda.empty_cache()\n",
    "    #     continue\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"err_loss: {err_loss}\")\n",
    "    print(f\"dist_loss: {dist_loss}\")\n",
    "    print(f\"curv_loss: {curv_loss}\")\n",
    "    torch.save(lane_keeper.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LaneKeeper(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 64, kernel_size=(7, 7), stride=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (lin): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lane_keeper.load_state_dict(torch.load(model_name))\n",
    "\n",
    "#save the model so that opencv can load it\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "device = torch.device('cpu')\n",
    "lane_keeper.to(device)\n",
    "\n",
    "# set the model to inference mode\n",
    "lane_keeper.eval()\n",
    "\n",
    "# Create some sample input in the shape this model expects \n",
    "# This is needed because the convertion forward pass the network once \n",
    "dummy_input = torch.randn(1, num_channels, SIZE[1], SIZE[0])\n",
    "torch.onnx.export(lane_keeper, dummy_input, onnx_lane_keeper_path, verbose=True)\n",
    "\n",
    "clear_output(wait=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "lane_keeper.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 549.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.03120236098766327\n",
      "Predictions: 0.014170300215482712\n",
      "Predictions: 0.00950879231095314\n",
      "Predictions: -0.01648910716176033\n",
      "Predictions: -0.015438403934240341\n",
      "Predictions: -0.00165615975856781\n",
      "Predictions: 0.004257243126630783\n",
      "Predictions: 0.02286888100206852\n",
      "Predictions: -0.0005987659096717834\n",
      "Predictions: -0.001325707882642746\n",
      "Predictions: -0.012493614107370377\n",
      "Predictions: -0.006192494183778763\n",
      "Predictions: 0.02901223488152027\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: -0.05044889077544212\n",
      "Predictions: -0.06375017762184143\n",
      "Predictions: -0.0544840432703495\n",
      "Predictions: -0.01858695223927498\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.02105346880853176\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.007312148809432983\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: -0.03683612868189812\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.02774074301123619\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 3.684563636779785\n",
      "Predictions: 2.78003191947937\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.035172946751117706\n",
      "Predictions: 0.04422302171587944\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 6.484355449676514\n",
      "Predictions: 0.15302252769470215\n",
      "Predictions: -0.16879740357398987\n",
      "Predictions: -0.020158801227808\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: -0.09100428223609924\n",
      "Predictions: -0.15807925164699554\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: -0.12444323301315308\n",
      "Predictions: -0.3036201596260071\n",
      "Predictions: 2.524003505706787\n",
      "Predictions: 0.3180721700191498\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.01387530192732811\n",
      "Predictions: 0.02168780192732811\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.044485654681921005\n",
      "Predictions: 0.011752236634492874\n",
      "Predictions: [[-0.01902512 -0.15394476  0.01175224 -0.0173618 ]]\n",
      "Predictions shape: (1, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#test with opencv\n",
    "sample_image = \"training_imgs/img_1.png\"\n",
    "images = [cv.imread(f\"training_imgs/img_{i+1}.png\") for i in range(100)]\n",
    " \n",
    "#The Magic:\n",
    "lk =  cv.dnn.readNetFromONNX(onnx_lane_keeper_path) \n",
    "\n",
    "avg_col = (0,0,0) if num_channels == 3 else 0\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    image = images[i]\n",
    "    image = cv.resize(image, SIZE)\n",
    "    if num_channels == 1:\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    blob = cv.dnn.blobFromImage(image, 1.0, SIZE, avg_col, swapRB=True, crop=False)\n",
    "    # print(blob.shape)\n",
    "    lk.setInput(blob)\n",
    "    preds = lk.forward()\n",
    "    print(f\"Predictions: {preds[0][2]}\")\n",
    "\n",
    "print(f\"Predictions: {preds}\")\n",
    "print(f\"Predictions shape: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get image and label\n",
    "# cv.namedWindow('img')\n",
    "# dataloader = DataLoader(train_dataset, batch_size=10000, shuffle=False)\n",
    "# for i, (imgs, labels) in enumerate(tqdm(dataloader)):\n",
    "#     #convert img to numpy\n",
    "#     imgs = imgs.cpu().numpy()\n",
    "#     for i in range(imgs.shape[0]):\n",
    "#         img = imgs[i][0]\n",
    "#         #convert to uint8d\n",
    "#         img = img.astype(np.uint8)\n",
    "#         cv.imshow(\"img\", img)\n",
    "#         cv.waitKey(1)\n",
    "\n",
    "# cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cee89b7c6bc96453738565335b56b694d8a30ac65e979633b683f8408c8233c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('dl_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
