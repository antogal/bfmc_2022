{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px # this is another plotting library for interactive plot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, manifold # we will use the metrics and manifold learning modules from scikit-learn\n",
    "from pathlib import Path # to interact with file paths\n",
    "from PIL import Image # to interact with images\n",
    "from tqdm import tqdm # progress bar\n",
    "from pprint import pprint # pretty print (useful for a more readable print of objects like lists or dictionaries)\n",
    "from IPython.display import clear_output # to clear the output of the notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2 as cv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTROL\n",
    "num_channels = 1\n",
    "SIZE = (32,32)\n",
    "model_name = 'models/lane_keeper_small.pt'\n",
    "onnx_lane_keeper_path = \"models/lane_keeper_small.onnx\"\n",
    "max_load = 15_000 #note: it will be get multiplied by 2 since imgs gets flipped with negative labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Net and create Detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NETWORK ARCHITECTURE\n",
    "\n",
    "# class LaneKeeper(nn.Module):\n",
    "#     def __init__(self, out_dim=4, channels=1): \n",
    "#         super().__init__()\n",
    "#         ### Convoluational layers\n",
    "#         self.conv = nn.Sequential( #in = (SIZE)\n",
    "#             nn.Conv2d(channels, 16, kernel_size=3, stride=1), #out = 30\n",
    "#             nn.ReLU(True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2), #out=15\n",
    "#             nn.BatchNorm2d(16),\n",
    "#             nn.Conv2d(16, 8, kernel_size=5, stride=2), #out = 12\n",
    "#             nn.ReLU(True),\n",
    "#             # nn.MaxPool2d(kernel_size=2, stride=2), #out=6\n",
    "#             # nn.BatchNorm2d(8),\n",
    "#             nn.Conv2d(8, 16, kernel_size=6, stride=1), #out = 1\n",
    "#             nn.ReLU(True),\n",
    "#         )\n",
    "#         self.flat = nn.Flatten()\n",
    "#         ### Linear sections\n",
    "#         self.lin = nn.Sequential(\n",
    "#             # First linear layer\n",
    "#             nn.Linear(in_features=1*1*16, out_features=64),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Linear(in_features=64, out_features=out_dim),\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv(x)\n",
    "#         x = self.flat(x)\n",
    "#         x = self.lin(x)\n",
    "#         return x\n",
    "\n",
    "# lane_keeper = LaneKeeper(out_dim=3,channels=num_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK ARCHITECTURE\n",
    "\n",
    "class LaneKeeper(nn.Module):\n",
    "    def __init__(self, out_dim=4, channels=1): \n",
    "        super().__init__()\n",
    "        ### Convoluational layers\n",
    "        self.conv = nn.Sequential( #in = (SIZE)\n",
    "            nn.Conv2d(channels, 8, kernel_size=5, stride=1), #out = 30\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), #out=15\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(8, 4, kernel_size=5, stride=1), #out = 12\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1), #out=11\n",
    "            # nn.BatchNorm2d(4),\n",
    "            nn.Conv2d(4, 4, kernel_size=6, stride=1), #out = 6\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.flat = nn.Flatten()\n",
    "        ### Linear sections\n",
    "        self.lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=4*4*4, out_features=16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(in_features=16, out_features=out_dim),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "lane_keeper = LaneKeeper(out_dim=3,channels=num_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32, 32])\n",
      "out shape: torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "# TEST NET INPUTS/OUTPUTS\n",
    "#show the image with opencv\n",
    "img = cv.imread('tests/test_img.jpg')\n",
    "img = cv.resize(img, SIZE)\n",
    "if num_channels == 1:\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "#convert to tensor\n",
    "img = torch.from_numpy(img).float()\n",
    "img = img.permute(2,0,1)\n",
    "#add dimension\n",
    "img = img.unsqueeze(0).to(device)\n",
    "print(img.shape)\n",
    "\n",
    "lane_keeper.eval()\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    output = lane_keeper(img)\n",
    "    print(f'out shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG LOADER AND AUGMENTATION\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_and_augment_img(img, folder='training_imgs'):\n",
    "    # img = cv.imread(os.path.join(folder, f'img_{i+1}.png'))\n",
    "\n",
    "    #convert to gray\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    #create random ellipses to simulate light from the sun\n",
    "    light = np.zeros(img.shape, dtype=np.uint8)\n",
    "    #add ellipses\n",
    "    for j in range(2):\n",
    "        cent = (np.random.randint(0, img.shape[0]), np.random.randint(0, img.shape[1]))\n",
    "        axes_length = (np.random.randint(10, 50), np.random.randint(50, 300))\n",
    "        angle = np.random.randint(0, 360)\n",
    "        light = cv.ellipse(light, cent, axes_length, angle, 0, 360, 255, -1)\n",
    "    #create an image of random white and black pixels\n",
    "    light = cv.blur(light, (100,100))\n",
    "    noise = np.random.randint(0, 2, size=img.shape, dtype=np.uint8)*255\n",
    "    light = cv.subtract(light, noise)\n",
    "    light = 5 * light\n",
    "\n",
    "    #add light to the image\n",
    "    img = cv.add(img, light)\n",
    "\n",
    "    # cv.imshow('light', light)\n",
    "    # if cv.waitKey(0) == ord('q'):\n",
    "    #     break\n",
    "\n",
    "    #blur the image\n",
    "    img = cv.blur(img, (9,9))\n",
    "\n",
    "    # cut the top third of the image, let it 640x320\n",
    "    img = img[int(img.shape[0]/3):,:]\n",
    "    assert img.shape == (320,640), f'img shape cut = {img.shape}'\n",
    "    #resize \n",
    "    img = cv.resize(img, SIZE)\n",
    "\n",
    "    #add random tilt\n",
    "    max_offset = 5\n",
    "    offset = np.random.randint(-max_offset, max_offset)\n",
    "    img = np.roll(img, offset, axis=0)\n",
    "    if offset > 0:\n",
    "        img[:offset, :] = np.random.randint(0,255)\n",
    "    elif offset < 0:\n",
    "        img[offset:, :] = np.random.randint(0,255)\n",
    "\n",
    "    #reduce contrast\n",
    "    const = np.random.uniform(0.1,1.2)\n",
    "    if np.random.uniform() > 5:\n",
    "        const = const*0.2\n",
    "    img = 127*(1-const) + img*const\n",
    "    img = img.astype(np.uint8)\n",
    "\n",
    "    #add noise \n",
    "    std = 150\n",
    "    std = np.random.randint(1, std)\n",
    "    noisem = np.random.randint(0, std, img.shape, dtype=np.uint8)\n",
    "    img = cv.subtract(img, noisem)\n",
    "    noisep = np.random.randint(0, std, img.shape, dtype=np.uint8)\n",
    "    img = cv.add(img, noisep)\n",
    "    #blur \n",
    "    img = cv.blur(img, (np.random.randint(1,3),np.random.randint(1,3)))\n",
    "\n",
    "    #add random brightness\n",
    "    max_brightness = 50\n",
    "    brightness = np.random.randint(-max_brightness, max_brightness)\n",
    "    if brightness > 0:\n",
    "        img = cv.add(img, brightness)\n",
    "    elif brightness < 0:\n",
    "        img = cv.subtract(img, -brightness)\n",
    "    \n",
    "    # # invert color\n",
    "    # if np.random.uniform(0, 1) > 0.6:\n",
    "    #     img = cv.bitwise_not(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "cv.namedWindow('img', cv.WINDOW_NORMAL)\n",
    "# cv.setWindowProperty('img', cv.WND_PROP_FULLSCREEN, cv.WINDOW_FULLSCREEN)\n",
    "\n",
    "for i in range(500):\n",
    "    img = cv.imread(os.path.join('training_imgs', f'img_{i+1}.png'))\n",
    "    img = load_and_augment_img(img)\n",
    "    cv.imshow('img', img)\n",
    "    key = cv.waitKey(100)\n",
    "    if key == ord('q') or key == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET CLASS\n",
    "class CsvDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None, max_load=1000, channels=3):\n",
    "        self.transform = transform\n",
    "        self.folder = folder\n",
    "        self.data = []\n",
    "        self.channels = channels\n",
    "\n",
    "        #classification label for road ahead = 1,0,0,0,1,0,0,0,0,0,0,0,0,0,0\n",
    "        road_images_indexes = []\n",
    "        tot_lines = 0\n",
    "        with open(folder+'/classification_labels.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            tot_lines = len(lines)\n",
    "            for i,line in enumerate(lines):\n",
    "                if line == '1,0,0,0,1,0,0,0,0,0,0,0,0,0,0':\n",
    "                    road_images_indexes.append(i)\n",
    "        print(f'total pure road images: {len(road_images_indexes)}')\n",
    "        road_imgs_mask = np.zeros(tot_lines, dtype=np.bool)\n",
    "        road_imgs_mask[road_images_indexes] = True\n",
    "\n",
    "        with open(folder+'/regression_labels.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            # Get x and y values from each line and append to self.data\n",
    "            max_load = min(max_load, len(lines))\n",
    "            # self.all_imgs = torch.zeros((2*max_load, SIZE[1], SIZE[0], channels), dtype=torch.uint8) #adding flipped img\n",
    "            self.all_imgs = torch.zeros((max_load, SIZE[1], SIZE[0], channels), dtype=torch.uint8)\n",
    "\n",
    "            # road images specifically are added again along with their flipped image and label\n",
    "            road_imgs = torch.zeros((2*len(road_images_indexes), SIZE[1], SIZE[0], channels), dtype=torch.uint8)\n",
    "            road_labels = []\n",
    "\n",
    "            cv.namedWindow('img', cv.WINDOW_NORMAL)\n",
    "            # cv.setWindowProperty('img', cv.WND_PROP_FULLSCREEN, cv.WINDOW_FULLSCREEN)\n",
    "            road_idx = 0\n",
    "            all_img_idx = 0\n",
    "            for i in tqdm(range(max_load)):\n",
    "\n",
    "                #label\n",
    "                line = lines[i]\n",
    "                sample = line.split(',')\n",
    "                #keep only info related to the lane, discard distance from stop line \n",
    "                sample = [sample[0], sample[1], sample[3]] #e2=lateral error, e3=yaw error point ahead, curvature\n",
    "                reg_label = np.array([float(s) for s in sample], dtype=np.float32)\n",
    "\n",
    "                #img \n",
    "                img = cv.imread(os.path.join(folder, f'img_{i+1}.png'))\n",
    "\n",
    "                #check if its in the road images\n",
    "                if road_imgs_mask[i]:\n",
    "                    img_r = load_and_augment_img(img.copy())\n",
    "                    # cv.imshow('imgR', img_r)\n",
    "                    img_r = img_r[:,:,np.newaxis]\n",
    "\n",
    "                    img_l = cv.flip(img, 1)\n",
    "                    img_l = load_and_augment_img(img_l)\n",
    "                    # cv.imshow('imgL', img_l)\n",
    "                    img_l = img_l[:,:,np.newaxis]\n",
    "                    # cv.waitKey(1)\n",
    "\n",
    "                    road_imgs[2*road_idx] = torch.from_numpy(img_r)\n",
    "                    road_imgs[2*road_idx+1] = torch.from_numpy(img_l)\n",
    "                    road_labels.append(reg_label)\n",
    "                    road_labels.append(-reg_label)\n",
    "                    road_idx += 1\n",
    "\n",
    "                else:\n",
    "                    img = load_and_augment_img(img)\n",
    "                    if i < 100:\n",
    "                        cv.imshow('img', img)\n",
    "                        cv.waitKey(1)\n",
    "                        if i == 99:\n",
    "                            cv.destroyAllWindows()\n",
    "                    #add a dimension to the image\n",
    "                    img = img[:, :,np.newaxis]\n",
    "                    self.all_imgs[all_img_idx] = torch.from_numpy(img)\n",
    "                    self.data.append(reg_label)\n",
    "                    all_img_idx += 1\n",
    "\n",
    "            #cut imgs to the right length\n",
    "            road_imgs = road_imgs[:2*road_idx]\n",
    "            self.all_imgs = self.all_imgs[:all_img_idx]\n",
    "\n",
    "            #concatenate all_imgs and road_imgs\n",
    "            print(f'road images: {road_imgs.shape}')\n",
    "            print(f'all images: {self.all_imgs.shape}')\n",
    "            self.all_imgs = torch.cat((self.all_imgs, road_imgs), dim=0)\n",
    "            print(f'self.data shape: {len(self.data)}')\n",
    "            print(f'road_labels shape = {len(road_labels)}')\n",
    "            self.data = np.concatenate((np.array(self.data), np.array(road_labels)), axis=0)\n",
    "\n",
    "            print(f'\\nall imgs: {self.all_imgs.shape}')\n",
    "            print(f'data: {self.data.shape}')\n",
    "\n",
    "            #free road_imgs from memory\n",
    "            del road_imgs\n",
    "            del road_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        # The length of the dataset is simply the length of the self.data list\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # img = read_image(os.path.join(self.folder, f'img_{idx+1}.png'))\n",
    "        # img = img.float()\n",
    "        img = self.all_imgs[idx]\n",
    "        img = img.permute(2, 0, 1).float()\n",
    "        value = self.data[idx]\n",
    "        return img, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "road images: 79427\n",
      "road images mask: 79427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [02:31<00:00, 99.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "road images: torch.Size([15812, 32, 32, 1])\n",
      "all images: torch.Size([7094, 32, 32, 1])\n",
      "self.data shape: 7094\n",
      "road_labels shape = 15812\n",
      "\n",
      "all imgs: torch.Size([22906, 32, 32, 1])\n",
      "data: (22906, 3)\n"
     ]
    }
   ],
   "source": [
    "#create dataset #takes a long time but then training is faster\n",
    "train_dataset = CsvDataset('training_imgs', max_load=max_load, channels=num_channels)\n",
    "#split dataset into train and val\n",
    "train_size = int(0.9*len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4096, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 1, 32, 32])\n",
      "torch.Size([4096, 3])\n"
     ]
    }
   ],
   "source": [
    "#test dataloader\n",
    "sample = next(iter(train_dataloader))\n",
    "print(sample[0].shape)\n",
    "print(sample[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING FUNCTION\n",
    "def train_epoch(model, dataloader, regr_loss_fn, optimizer, device=device):\n",
    "    # Set the model to training mode\n",
    "    model.train() #train\n",
    "    # Initialize the loss\n",
    "    err_losses2 = []\n",
    "    err_losses3 = []\n",
    "    curv_losses = []\n",
    "\n",
    "    # Loop over the training batches\n",
    "    for (input, regr_label) in tqdm(dataloader):\n",
    "        # Move the input and target data to the selected device\n",
    "        input, regr_label =input.to(device), regr_label.to(device)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the output\n",
    "        output = model(input)\n",
    "\n",
    "        #regression\n",
    "        err2 = output[:, 0]\n",
    "        err3 = output[:, 1]\n",
    "        curv_out = output[:, 2]\n",
    "\n",
    "        err2_label = regr_label[:, 0]\n",
    "        err3_label = regr_label[:, 1]\n",
    "        curv_label = regr_label[:, 2]\n",
    "\n",
    "        # Compute the losses\n",
    "        err_loss2 = 1.0*regr_loss_fn(err2, err2_label)\n",
    "        err_loss3 = 1.0*regr_loss_fn(err3, err3_label)\n",
    "        curv_loss = 1.0*regr_loss_fn(curv_out, curv_label)\n",
    "        loss = err_loss3 + err_loss2 + curv_loss\n",
    "\n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #batch loss\n",
    "        err_losses2.append(err_loss2.detach().cpu().numpy())\n",
    "        err_losses3.append(err_loss3.detach().cpu().numpy())\n",
    "        curv_losses.append(curv_loss.detach().cpu().numpy())\n",
    "\n",
    "    # Return the average training loss\n",
    "    err_loss2 = np.mean(err_losses2)\n",
    "    err_loss3 = np.mean(err_losses3)\n",
    "    curv_loss = np.mean(curv_losses)\n",
    "    return err_loss2, err_loss3, curv_loss\n",
    "\n",
    "    # VALIDATION FUNCTION\n",
    "def val_epoch(lane_keeper, val_dataloader, regr_loss_fn, device=device):\n",
    "    lane_keeper.eval()\n",
    "    err_losses3 = []\n",
    "    err_losses2 = []\n",
    "    curv_losses = []\n",
    "    for (input, regr_label) in tqdm(val_dataloader):\n",
    "        input, regr_label =input.to(device), regr_label.to(device)\n",
    "        output = lane_keeper(input)\n",
    "\n",
    "        regr_out = output\n",
    "        err2 = regr_out[:, 0]\n",
    "        err3 = regr_out[:, 1]\n",
    "        curv_out = regr_out[:, 2]\n",
    "\n",
    "        err2_label = regr_label[:, 0]\n",
    "        err3_label = regr_label[:, 1]\n",
    "        curv_label = regr_label[:, 2]\n",
    "\n",
    "        err_loss3 = 1.0*regr_loss_fn(err3, err3_label)\n",
    "        err_loss2 = 1.0*regr_loss_fn(err2, err2_label)\n",
    "        curv_loss = 1.0*regr_loss_fn(curv_out, curv_label)\n",
    "        loss = err_loss3 + err_loss2 + curv_loss\n",
    "\n",
    "        err_losses2.append(err_loss2.detach().cpu().numpy())\n",
    "        err_losses3.append(err_loss3.detach().cpu().numpy())\n",
    "        curv_losses.append(curv_loss.detach().cpu().numpy())\n",
    "    return np.mean(err_losses2), np.mean(err_losses3), np.mean(curv_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  30/30 -> yaw_err_loss3: 0.0173\n",
      "Validation loss e3: 0.0184\n"
     ]
    }
   ],
   "source": [
    "# TRAINING \n",
    "#parameters\n",
    "lr = 0.003 #0.005\n",
    "epochs = 30\n",
    "optimizer = torch.optim.Adam(lane_keeper.parameters(), lr=lr, weight_decay=2e-2) #wd = 2e-3# 3e-5\n",
    "regr_loss_fn = nn.MSELoss()\n",
    "for epoch in range(epochs):\n",
    "    try:\n",
    "    # if True:\n",
    "        err_loss2, err_loss3, curv_loss = train_epoch(lane_keeper, train_dataloader, regr_loss_fn, optimizer, device)\n",
    "        val_loss2, val_loss3, val_curv_loss = val_epoch(lane_keeper, val_dataloader, regr_loss_fn, device)\n",
    "        clear_output(wait=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        torch.cuda.empty_cache()\n",
    "        continue\n",
    "    print(f\"Epoch  {epoch+1}/{epochs} -> yaw_err_loss3: {err_loss3:.4f}\\nValidation loss e3: {val_loss3:.4f}\")\n",
    "    # print(f\"lateral_err_loss2: {err_loss2}\")\n",
    "    # print(f\"curv_loss: {curv_loss}\")\n",
    "    torch.save(lane_keeper.state_dict(), model_name)\n",
    "\n",
    "#Note: sweet spot for training is around 0.016 -> 0.020, also note that training can get stuck, and loss can start improve randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 81.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lateral_err2_loss: 0.002265975112095475\n",
      "yaw_err3_loss: 0.018373852595686913\n",
      "curv_loss: 0.0002776467881631106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE ON TEST SET (UNSEEN DATA)\n",
    "lane_keeper.eval()\n",
    "err_losses3 = []\n",
    "err_losses2 = []\n",
    "curv_losses = []\n",
    "for (input, regr_label) in tqdm(val_dataloader):\n",
    "    input, regr_label =input.to(device), regr_label.to(device)\n",
    "    output = lane_keeper(input)\n",
    "\n",
    "    regr_out = output\n",
    "    err2 = regr_out[:, 0]\n",
    "    err3 = regr_out[:, 1]\n",
    "    curv_out = regr_out[:, 2]\n",
    "\n",
    "    err2_label = regr_label[:, 0]\n",
    "    err3_label = regr_label[:, 1]\n",
    "    curv_label = regr_label[:, 2]\n",
    "\n",
    "    err_loss3 = 1.0*regr_loss_fn(err3, err3_label)\n",
    "    err_loss2 = 1.0*regr_loss_fn(err2, err2_label)\n",
    "    curv_loss = 1.0*regr_loss_fn(curv_out, curv_label)\n",
    "    loss = err_loss3 + err_loss2 + curv_loss\n",
    "\n",
    "    err_losses2.append(err_loss2.detach().cpu().numpy())\n",
    "    err_losses3.append(err_loss3.detach().cpu().numpy())\n",
    "    curv_losses.append(curv_loss.detach().cpu().numpy())\n",
    "\n",
    "print(f\"lateral_err2_loss: {np.mean(err_losses2)}\")\n",
    "print(f\"yaw_err3_loss: {np.mean(err_losses3)}\")\n",
    "print(f\"curv_loss: {np.mean(curv_losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1, 5, 5)\n",
      "(4, 8, 5, 5)\n",
      "(4, 4, 6, 6)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x1440 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# VISUALIZE CONVOLUTIONAL FILTERS\n",
    "conv_layers = []\n",
    "children = list(lane_keeper.children())\n",
    "for i in range(len(children)):\n",
    "    if isinstance(children[i], nn.Conv2d):\n",
    "        conv_layers.append(children[i])\n",
    "    elif isinstance(children[i], nn.Sequential):\n",
    "        for child in children[i].children():\n",
    "            if isinstance(child, nn.Conv2d):\n",
    "                conv_layers.append(child)\n",
    "\n",
    "c0 = conv_layers[0].weight.data.cpu().numpy()\n",
    "c1 = conv_layers[1].weight.data.cpu().numpy()\n",
    "c2 = conv_layers[2].weight.data.cpu().numpy()\n",
    "\n",
    "def plot_nchw_data(data, h_num, v_num, title, size=(10, 10)):\n",
    "    fig, axs = plt.subplots(h_num, v_num, figsize=size)\n",
    "    shape = data.shape\n",
    "    data = data.reshape(shape[0]*shape[1], shape[2], shape[3])\n",
    "    for idx, ax in enumerate(axs.flatten()):\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if idx < len(data):\n",
    "            ax.imshow(data[idx,:,:], cmap='gray')\n",
    "    plt.suptitle(title)\n",
    "    #plt.tight_layout(rect=[0, 0, 1, 0.97], h_pad=0, w_pad=0)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "# fig0 = plot_nchw_data(c0, 4, 4, 'conv0')\n",
    "print(c0.shape)\n",
    "print(c1.shape)\n",
    "print(c2.shape)\n",
    "\n",
    "fig0 = plot_nchw_data(c0, 2, 4, 'conv0', size=(10,5))\n",
    "\n",
    "fig1 = plot_nchw_data(c1, 8, 4, 'conv1', size=(10,20)) \n",
    "\n",
    "fig2 = plot_nchw_data(c2, 4, 4, 'conv2', size=(10,10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LaneKeeper(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Conv2d(8, 4, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(4, 4, kernel_size=(6, 6), stride=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "  )\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (lin): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=16, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=16, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT TO ONNX MODEL FOR OPENCV\n",
    "lane_keeper.load_state_dict(torch.load(model_name))\n",
    "\n",
    "#save the model so that opencv can load it\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "device = torch.device('cpu')\n",
    "lane_keeper.to(device)\n",
    "\n",
    "# set the model to inference mode\n",
    "lane_keeper.eval()\n",
    "\n",
    "# Create some sample input in the shape this model expects \n",
    "# This is needed because the convertion forward pass the network once \n",
    "dummy_input = torch.randn(1, num_channels, SIZE[1], SIZE[0])\n",
    "torch.onnx.export(lane_keeper, dummy_input, onnx_lane_keeper_path, verbose=True)\n",
    "\n",
    "clear_output(wait=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "lane_keeper.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 2734.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[-1.005888e-03 -1.502794e-02  7.770024e-05]]\n",
      "Predictions shape: (1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST WITH OPENCV\n",
    "sample_image = \"training_imgs/img_1.png\"\n",
    "images = [cv.imread(f\"training_imgs/img_{i+1}.png\") for i in range(100)]\n",
    " \n",
    "#The Magic:\n",
    "lk =  cv.dnn.readNetFromONNX(onnx_lane_keeper_path) \n",
    "\n",
    "avg_col = (0,0,0) if num_channels == 3 else 0\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    image = images[i]\n",
    "    image = cv.resize(image, SIZE)\n",
    "    if num_channels == 1:\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    blob = cv.dnn.blobFromImage(image, 1.0, SIZE, avg_col, swapRB=True, crop=False)\n",
    "    # print(blob.shape)\n",
    "    lk.setInput(blob)\n",
    "    preds = lk.forward()\n",
    "    # print(f\"Predictions: {preds[0][2]}\")\n",
    "\n",
    "print(f\"Predictions: {preds}\")\n",
    "print(f\"Predictions shape: {preds.shape}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cee89b7c6bc96453738565335b56b694d8a30ac65e979633b683f8408c8233c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('dl_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
