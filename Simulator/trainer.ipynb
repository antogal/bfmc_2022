{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px # this is another plotting library for interactive plot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, manifold # we will use the metrics and manifold learning modules from scikit-learn\n",
    "from pathlib import Path # to interact with file paths\n",
    "from PIL import Image # to interact with images\n",
    "from tqdm import tqdm # progress bar\n",
    "from pprint import pprint # pretty print (useful for a more readable print of objects like lists or dictionaries)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2 as cv\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Net and create Detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/irong/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-2-17 torch 1.10.0+cu113 CUDA:0 (NVIDIA GeForce GTX 950M, 2004MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Detector(\n",
       "  (lin): Sequential(\n",
       "    (0): Linear(in_features=20484, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=512, out_features=35, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True) #faster but less accurate\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True) \n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5n6', pretrained=True) \n",
    "# model = torch.hub.load('ultralytics/yolov3', 'yolov3') #bad \n",
    "model.to(device)\n",
    "\n",
    "# Analyze network\n",
    "\n",
    "# print(model)\n",
    "\n",
    "# for param_name, param in model.named_parameters():\n",
    "#     print(param_name)\n",
    "\n",
    "# for i, (k, v) in enumerate(model.named_parameters()):\n",
    "#     print(f'{i} - {k}')\n",
    "\n",
    "#https://github.com/ultralytics/yolov5/issues/1314\n",
    "\n",
    "#backnbone is layers 0->9\n",
    "\n",
    "backbone_layers = [f'model.{x}' for x in range(9)]\n",
    "\n",
    "backbone = nn.Sequential(\n",
    "    model.model.model.model[0],\n",
    "    model.model.model.model[1],\n",
    "    model.model.model.model[2],\n",
    "    model.model.model.model[3],\n",
    "    model.model.model.model[4],\n",
    "    model.model.model.model[5],\n",
    "    model.model.model.model[6],\n",
    "    model.model.model.model[7],\n",
    "    model.model.model.model[8],\n",
    "    model.model.model.model[9],\n",
    "    model.model.model.model[10],\n",
    "    )\n",
    "\n",
    "# print(backbone)\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, backbone): #(default for 640x320)\n",
    "        super().__init__()\n",
    "\n",
    "        ## Pretrained layers\n",
    "        self.pretrained = backbone\n",
    "\n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutions\n",
    "        x = self.pretrained(x)\n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "        return x\n",
    "\n",
    "class Detector(nn.Module):\n",
    "    def __init__(self, add_inputs=4, regr_out=22, class_out=13, features=76800): #(default for 640x320)\n",
    "        super().__init__()\n",
    "        ### Linear sections\n",
    "        self.lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=features+add_inputs, out_features=512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(in_features=512, out_features=regr_out+class_out),\n",
    "        )\n",
    "        # #regression output\n",
    "        # self.lin_regr = nn.Sequential(\n",
    "        #     # First linear layer\n",
    "        #     nn.Linear(in_features=1024, out_features=512),\n",
    "        #     nn.ReLU(True),\n",
    "        #     # nn.Dropout(p=0.5),\n",
    "        #     # Second linear\n",
    "        #     nn.Linear(in_features=512, out_features=regr_out)\n",
    "        # )\n",
    "        # # classification output\n",
    "        # self.lin_class = nn.Sequential(\n",
    "        #     # First linear layer\n",
    "        #     nn.Linear(in_features=1024, out_features=512),\n",
    "        #     nn.ReLU(True),\n",
    "        #     # nn.Dropout(p=0.5),\n",
    "        #     # Second linear\n",
    "        #     nn.Linear(in_features=512, out_features=class_out)\n",
    "        # )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "feature_extractor=FeatureExtractor(backbone)\n",
    "#define detector\n",
    "detector = Detector(add_inputs=4, regr_out=22, class_out=13, features=20480)\n",
    "\n",
    "#freeeze backbone\n",
    "for param in feature_extractor.pretrained.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "feature_extractor.to(device)\n",
    "detector.to(device)\n",
    "\n",
    "# #check\n",
    "# for param_name, param in detector.named_parameters():\n",
    "#     print('%s \\t- requires_grad=%s' % (param_name, param.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 240, 320])\n",
      "torch.Size([1, 20484])\n",
      "torch.Size([1, 35])\n"
     ]
    }
   ],
   "source": [
    "# test backbone\n",
    "#show the image with opencv\n",
    "img = cv.imread('tests/test_img.jpg')\n",
    "#resize to 480 x 640\n",
    "img = cv.resize(img, (320, 240))\n",
    "#convert to tensor\n",
    "img = torch.from_numpy(img).float().permute(2, 0, 1)\n",
    "#add dimension\n",
    "img = img.unsqueeze(0).to(device)\n",
    "print(img.shape)\n",
    "\n",
    "detector.eval()\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    data = torch.zeros(1, 4).to(device)\n",
    "    feat = feature_extractor(img)\n",
    "    input = torch.cat((feat, data), dim=1)\n",
    "    print(input.shape)\n",
    "    out = detector(input) \n",
    "    print(out.shape) # (320, 240)->torch.Size([1, 20480])\n",
    "                    # (640, 480)->torch.Size([1, 76800])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2878/2878 [00:00<00:00, 48728.45it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2878/2878 [00:00<00:00, 44083.01it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2878/2878 [00:13<00:00, 212.13it/s]\n"
     ]
    }
   ],
   "source": [
    "#dataset\n",
    "class CsvDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        class_labels = []\n",
    "        with open(folder+'/classification_labels.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            # Get x and y values from each line and append to self.data\n",
    "            labels = []\n",
    "            for i in tqdm(range(len(lines))):\n",
    "                line = lines[i]\n",
    "                sample = line.split(',')\n",
    "                #convert to float\n",
    "                label = np.array([float(s) for s in sample])\n",
    "                #convert to tensor\n",
    "                label = torch.from_numpy(label).float()\n",
    "                # img = img.unsqueeze(0)\n",
    "                class_labels.append(label)\n",
    "\n",
    "        input_data = []\n",
    "        with open(folder+'/input_data.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            # Get x and y values from each line and append to self.data\n",
    "            labels = []\n",
    "            for i in tqdm(range(len(lines))):\n",
    "                line = lines[i]\n",
    "                sample = line.split(',')\n",
    "                #convert to float\n",
    "                label = np.array([float(s) for s in sample])\n",
    "                #convert to tensor\n",
    "                label = torch.from_numpy(label).float()\n",
    "                # img = img.unsqueeze(0)\n",
    "                input_data.append(label)\n",
    "\n",
    "        #load labels\n",
    "        with open(folder+'/regression_labels.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            # Get x and y values from each line and append to self.data\n",
    "            labels = []\n",
    "            for i in tqdm(range(len(lines))):\n",
    "                line = lines[i]\n",
    "                sample = line.split(',')\n",
    "                #convert to float\n",
    "                label = np.array([float(s) for s in sample])\n",
    "                #convert to tensor\n",
    "                label = torch.from_numpy(label).float()\n",
    "                #load img\n",
    "                img = cv.imread(folder+f'/img_{i+1}.png')\n",
    "                img = cv.resize(img, (320, 240))\n",
    "                img = torch.from_numpy(img).float().permute(2, 0, 1)\n",
    "                # img = img.unsqueeze(0)\n",
    "                self.data.append((img, input_data[i], label, class_labels[i]))\n",
    "                \n",
    "    def __len__(self):\n",
    "        # The length of the dataset is simply the length of the self.data list\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Our sample is the element idx of the list self.data\n",
    "        sample = self.data[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "#create dataset\n",
    "train_dataset = CsvDataset(folder='training_imgs')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(ext, det, dataloader, class_loss_fn, regr_loss_fn, optimizer, device):\n",
    "    # Set the model to training mode\n",
    "    ext.eval() #dont train the extractor\n",
    "    det.train() #train detector\n",
    "    # Initialize the loss\n",
    "    train_loss_class = []\n",
    "    train_loss_regr = []\n",
    "    # Loop over the training batches\n",
    "    for (img, input_data, regr_label, class_label) in dataloader:\n",
    "        # Move the input and target data to the selected device\n",
    "        img, input_data, regr_label, class_label = img.to(device), input_data.to(device), regr_label.to(device), class_label.to(device)\n",
    "        # Compute the features\n",
    "        features = ext(img)\n",
    "        #concatenate features and input_data\n",
    "        input = torch.cat((features, input_data), dim=1)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the output\n",
    "        output = det(input)\n",
    "\n",
    "        #regression 22 values\n",
    "        #classification: 3 states, 3 next states, 7 signs\n",
    "        regr_out = output[:, :22]\n",
    "        state_out = output[:, 22:25]\n",
    "        next_out = output[:, 25:28]\n",
    "        sign_out = output[:, 28:]\n",
    "        \n",
    "        state_label = class_label[:, :3]\n",
    "        next_label = class_label[:, 3:6]\n",
    "        sign_label = class_label[:, 6:]\n",
    "\n",
    "        # Compute the losses\n",
    "        regr_loss = 5.0*regr_loss_fn(regr_out, regr_label)\n",
    "        state_loss = class_loss_fn(state_out, state_label)\n",
    "        next_loss = class_loss_fn(next_out, next_label)\n",
    "        sign_loss = class_loss_fn(sign_out, sign_label)\n",
    "        loss = regr_loss + state_loss + next_loss + sign_loss\n",
    "\n",
    "        \n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        #batch loss\n",
    "        c_loss = (state_loss + next_loss + sign_loss).detach().cpu().numpy()\n",
    "        r_loss = regr_loss.detach().cpu().numpy()\n",
    "        train_loss_class.append(c_loss)\n",
    "        train_loss_regr.append(r_loss)\n",
    "    # Return the average training loss\n",
    "    train_loss_c = np.mean(train_loss_class)\n",
    "    train_loss_r = np.mean(train_loss_regr)\n",
    "    # print(f\"Training loss: {train_loss}\")\n",
    "    return train_loss_c, train_loss_r\n",
    "\n",
    "def get_avg_loss(ext, det, dataloader, class_loss_fn, regr_loss_fn, device):\n",
    "    ext.eval()\n",
    "    det.eval()\n",
    "    class_losses = []\n",
    "    regr_losses = []\n",
    "    with torch.no_grad():\n",
    "        for (img, input_data, regr_label, class_label) in dataloader:\n",
    "            # Move the input and target data to the selected device\n",
    "            img, input_data, regr_label, class_label = img.to(device), input_data.to(device), regr_label.to(device), class_label.to(device)\n",
    "            # Compute the features\n",
    "            features = ext(img)\n",
    "            #concatenate features and input_data\n",
    "            input = torch.cat((features, input_data), dim=1)\n",
    "            # Compute the output\n",
    "            output = det(input)\n",
    "            \n",
    "            #regression 22 values\n",
    "            #classification: 3 states, 3 next states, 7 signs\n",
    "            regr_out = output[:, :22]\n",
    "            state_out = output[:, 22:25]\n",
    "            next_out = output[:, 25:28]\n",
    "            sign_out = output[:, 28:]\n",
    "            \n",
    "            state_label = class_label[:, :3]\n",
    "            next_label = class_label[:, 3:6]\n",
    "            sign_label = class_label[:, 6:]\n",
    "\n",
    "            # Compute the losses\n",
    "            regr_loss = regr_loss_fn(regr_out, regr_label)\n",
    "            state_loss = class_loss_fn(state_out, state_label)\n",
    "            next_loss = class_loss_fn(next_out, next_label)\n",
    "            sign_loss = class_loss_fn(sign_out, sign_label)\n",
    "            class_loss = state_loss + next_loss + sign_loss\n",
    "\n",
    "            class_losses.append(class_loss.detach().cpu().numpy())\n",
    "            regr_losses.append(regr_loss.detach().cpu().numpy())\n",
    "    # Return the accuracy and test loss\n",
    "    class_loss = np.mean(class_losses)\n",
    "    regr_loss = np.mean(regr_losses)\n",
    "    return class_loss, regr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Regression loss: 1.383567452430725\n",
      "Classification loss: 0.5319092273712158\n",
      "Epoch 2/10\n",
      "Regression loss: 0.5856467485427856\n",
      "Classification loss: 0.15974725782871246\n",
      "Epoch 3/10\n",
      "Regression loss: 0.4529952108860016\n",
      "Classification loss: 0.08969224244356155\n",
      "Epoch 4/10\n",
      "Regression loss: 0.32902899384498596\n",
      "Classification loss: 0.052130065858364105\n",
      "Epoch 5/10\n",
      "Regression loss: 0.26006975769996643\n",
      "Classification loss: 0.03691543638706207\n",
      "Epoch 6/10\n",
      "Regression loss: 0.21560432016849518\n",
      "Classification loss: 0.02538921684026718\n",
      "Epoch 7/10\n",
      "Regression loss: 0.18115952610969543\n",
      "Classification loss: 0.017120476812124252\n",
      "Epoch 8/10\n",
      "Regression loss: 0.16349801421165466\n",
      "Classification loss: 0.013205996714532375\n",
      "Epoch 9/10\n",
      "Regression loss: 0.1333140879869461\n",
      "Classification loss: 0.010985524393618107\n",
      "Epoch 10/10\n",
      "Regression loss: 0.1297859102487564\n",
      "Classification loss: 0.00826309435069561\n"
     ]
    }
   ],
   "source": [
    "#load models\n",
    "detector.load_state_dict(torch.load('detector.pt'))\n",
    "feature_extractor.load_state_dict(torch.load('feature_extractor.pt'))\n",
    "\n",
    "#parameters\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "optimizer = torch.optim.Adam(detector.parameters(), lr=lr)\n",
    "regr_loss_fn = nn.MSELoss()\n",
    "class_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    class_loss, regr_loss = train_epoch(feature_extractor, detector, train_dataloader, class_loss_fn, regr_loss_fn, optimizer, device)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Regression loss: {regr_loss}\")\n",
    "    print(f\"Classification loss: {class_loss}\")\n",
    "    torch.save(detector.state_dict(), 'detector.pt')\n",
    "    torch.save(feature_extractor.state_dict(), 'feature_extractor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2878/2878 [00:00<00:00, 37794.45it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2878/2878 [00:00<00:00, 64085.49it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2878/2878 [00:16<00:00, 173.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification loss: 0.008194329217076302\n",
      "Training regression loss: 0.028632866218686104\n",
      "\n",
      "Testing classification loss: 0.008201380260288715\n",
      "Testing regression loss: 0.028721364215016365\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "test_dataset = CsvDataset(folder='test_imgs')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "#get accuracy\n",
    "train_class_loss, train_regr_loss = get_avg_loss(feature_extractor, detector, train_dataloader, class_loss_fn, regr_loss_fn, device)\n",
    "test_class_loss, test_regr_loss = get_avg_loss(feature_extractor, detector, test_dataloader, class_loss_fn, regr_loss_fn, device)\n",
    "\n",
    "print(f\"Training classification loss: {train_class_loss}\")\n",
    "print(f\"Training regression loss: {train_regr_loss}\\n\")\n",
    "print(f\"Testing classification loss: {test_class_loss}\")\n",
    "print(f\"Testing regression loss: {test_regr_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 240, 320])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input.1 : Float(1, 3, 240, 320, strides=[230400, 76800, 320, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.0.conv.weight : Float(32, 3, 6, 6, strides=[108, 36, 6, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.0.conv.bias : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.1.conv.weight : Float(64, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.1.conv.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.cv1.conv.weight : Float(32, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.cv1.conv.bias : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.cv2.conv.weight : Float(32, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.cv2.conv.bias : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.cv3.conv.weight : Float(64, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.cv3.conv.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.m.0.cv1.conv.weight : Float(32, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.m.0.cv1.conv.bias : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.m.0.cv2.conv.weight : Float(32, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.m.0.cv2.conv.bias : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.3.conv.weight : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.3.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.cv1.conv.weight : Float(64, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.cv1.conv.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.cv2.conv.weight : Float(64, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.cv2.conv.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.cv3.conv.weight : Float(128, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.cv3.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.m.0.cv1.conv.weight : Float(64, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.m.0.cv1.conv.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.m.0.cv2.conv.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.m.0.cv2.conv.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.m.1.cv1.conv.weight : Float(64, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.m.1.cv1.conv.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.m.1.cv2.conv.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.m.1.cv2.conv.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.5.conv.weight : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.5.conv.bias : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.cv1.conv.weight : Float(128, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.cv1.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.cv2.conv.weight : Float(128, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.cv2.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.cv3.conv.weight : Float(256, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.cv3.conv.bias : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.0.cv1.conv.weight : Float(128, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.0.cv1.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.0.cv2.conv.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.0.cv2.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.1.cv1.conv.weight : Float(128, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.1.cv1.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.1.cv2.conv.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.1.cv2.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.2.cv1.conv.weight : Float(128, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.2.cv1.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.2.cv2.conv.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.2.cv2.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.7.conv.weight : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.7.conv.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.cv1.conv.weight : Float(256, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.cv1.conv.bias : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.cv2.conv.weight : Float(256, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.cv2.conv.bias : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.cv3.conv.weight : Float(512, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.cv3.conv.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.m.0.cv1.conv.weight : Float(256, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.m.0.cv1.conv.bias : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.m.0.cv2.conv.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.m.0.cv2.conv.bias : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.9.cv1.conv.weight : Float(256, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.9.cv1.conv.bias : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.9.cv2.conv.weight : Float(512, 1024, 1, 1, strides=[1024, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.9.cv2.conv.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.10.conv.weight : Float(256, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.10.conv.bias : Float(256, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %69 : Float(1, 32, 120, 160, strides=[614400, 19200, 160, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[6, 6], pads=[2, 2, 2, 2], strides=[2, 2]](%input.1, %pretrained.0.conv.weight, %pretrained.0.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %70 : Float(1, 32, 120, 160, strides=[614400, 19200, 160, 1], device=cpu) = onnx::Sigmoid(%69)\n",
      "  %71 : Float(1, 32, 120, 160, strides=[614400, 19200, 160, 1], requires_grad=0, device=cpu) = onnx::Mul(%69, %70) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %72 : Float(1, 64, 60, 80, strides=[307200, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%71, %pretrained.1.conv.weight, %pretrained.1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %73 : Float(1, 64, 60, 80, strides=[307200, 4800, 80, 1], device=cpu) = onnx::Sigmoid(%72)\n",
      "  %74 : Float(1, 64, 60, 80, strides=[307200, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Mul(%72, %73) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %75 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%74, %pretrained.2.cv1.conv.weight, %pretrained.2.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %76 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], device=cpu) = onnx::Sigmoid(%75)\n",
      "  %77 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Mul(%75, %76) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %78 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%77, %pretrained.2.m.0.cv1.conv.weight, %pretrained.2.m.0.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %79 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], device=cpu) = onnx::Sigmoid(%78)\n",
      "  %80 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Mul(%78, %79) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %81 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%80, %pretrained.2.m.0.cv2.conv.weight, %pretrained.2.m.0.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %82 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], device=cpu) = onnx::Sigmoid(%81)\n",
      "  %83 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Mul(%81, %82) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %84 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Add(%77, %83) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:105:0\n",
      "  %85 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%74, %pretrained.2.cv2.conv.weight, %pretrained.2.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %86 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], device=cpu) = onnx::Sigmoid(%85)\n",
      "  %87 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Mul(%85, %86) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %88 : Float(1, 64, 60, 80, strides=[307200, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%84, %87) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:139:0\n",
      "  %89 : Float(1, 64, 60, 80, strides=[307200, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%88, %pretrained.2.cv3.conv.weight, %pretrained.2.cv3.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %90 : Float(1, 64, 60, 80, strides=[307200, 4800, 80, 1], device=cpu) = onnx::Sigmoid(%89)\n",
      "  %91 : Float(1, 64, 60, 80, strides=[307200, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Mul(%89, %90) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %92 : Float(1, 128, 30, 40, strides=[153600, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%91, %pretrained.3.conv.weight, %pretrained.3.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %93 : Float(1, 128, 30, 40, strides=[153600, 1200, 40, 1], device=cpu) = onnx::Sigmoid(%92)\n",
      "  %94 : Float(1, 128, 30, 40, strides=[153600, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Mul(%92, %93) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %95 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%94, %pretrained.4.cv1.conv.weight, %pretrained.4.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %96 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], device=cpu) = onnx::Sigmoid(%95)\n",
      "  %97 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Mul(%95, %96) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %98 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%97, %pretrained.4.m.0.cv1.conv.weight, %pretrained.4.m.0.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %99 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], device=cpu) = onnx::Sigmoid(%98)\n",
      "  %100 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Mul(%98, %99) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %101 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%100, %pretrained.4.m.0.cv2.conv.weight, %pretrained.4.m.0.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %102 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], device=cpu) = onnx::Sigmoid(%101)\n",
      "  %103 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Mul(%101, %102) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %104 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Add(%97, %103) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:105:0\n",
      "  %105 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%104, %pretrained.4.m.1.cv1.conv.weight, %pretrained.4.m.1.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %106 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], device=cpu) = onnx::Sigmoid(%105)\n",
      "  %107 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Mul(%105, %106) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %108 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%107, %pretrained.4.m.1.cv2.conv.weight, %pretrained.4.m.1.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %109 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], device=cpu) = onnx::Sigmoid(%108)\n",
      "  %110 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Mul(%108, %109) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %111 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Add(%104, %110) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:105:0\n",
      "  %112 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%94, %pretrained.4.cv2.conv.weight, %pretrained.4.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %113 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], device=cpu) = onnx::Sigmoid(%112)\n",
      "  %114 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Mul(%112, %113) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %115 : Float(1, 128, 30, 40, strides=[153600, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%111, %114) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:139:0\n",
      "  %116 : Float(1, 128, 30, 40, strides=[153600, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%115, %pretrained.4.cv3.conv.weight, %pretrained.4.cv3.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %117 : Float(1, 128, 30, 40, strides=[153600, 1200, 40, 1], device=cpu) = onnx::Sigmoid(%116)\n",
      "  %118 : Float(1, 128, 30, 40, strides=[153600, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Mul(%116, %117) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %119 : Float(1, 256, 15, 20, strides=[76800, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%118, %pretrained.5.conv.weight, %pretrained.5.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %120 : Float(1, 256, 15, 20, strides=[76800, 300, 20, 1], device=cpu) = onnx::Sigmoid(%119)\n",
      "  %121 : Float(1, 256, 15, 20, strides=[76800, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%119, %120) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %122 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%121, %pretrained.6.cv1.conv.weight, %pretrained.6.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %123 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], device=cpu) = onnx::Sigmoid(%122)\n",
      "  %124 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%122, %123) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %125 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%124, %pretrained.6.m.0.cv1.conv.weight, %pretrained.6.m.0.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %126 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], device=cpu) = onnx::Sigmoid(%125)\n",
      "  %127 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%125, %126) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %128 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%127, %pretrained.6.m.0.cv2.conv.weight, %pretrained.6.m.0.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %129 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], device=cpu) = onnx::Sigmoid(%128)\n",
      "  %130 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%128, %129) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %131 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Add(%124, %130) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:105:0\n",
      "  %132 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%131, %pretrained.6.m.1.cv1.conv.weight, %pretrained.6.m.1.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %133 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], device=cpu) = onnx::Sigmoid(%132)\n",
      "  %134 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%132, %133) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %135 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%134, %pretrained.6.m.1.cv2.conv.weight, %pretrained.6.m.1.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %136 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], device=cpu) = onnx::Sigmoid(%135)\n",
      "  %137 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%135, %136) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %138 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Add(%131, %137) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:105:0\n",
      "  %139 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%138, %pretrained.6.m.2.cv1.conv.weight, %pretrained.6.m.2.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %140 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], device=cpu) = onnx::Sigmoid(%139)\n",
      "  %141 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%139, %140) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %142 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%141, %pretrained.6.m.2.cv2.conv.weight, %pretrained.6.m.2.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %143 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], device=cpu) = onnx::Sigmoid(%142)\n",
      "  %144 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%142, %143) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %145 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Add(%138, %144) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:105:0\n",
      "  %146 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%121, %pretrained.6.cv2.conv.weight, %pretrained.6.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %147 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], device=cpu) = onnx::Sigmoid(%146)\n",
      "  %148 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%146, %147) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %149 : Float(1, 256, 15, 20, strides=[76800, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%145, %148) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:139:0\n",
      "  %150 : Float(1, 256, 15, 20, strides=[76800, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%149, %pretrained.6.cv3.conv.weight, %pretrained.6.cv3.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %151 : Float(1, 256, 15, 20, strides=[76800, 300, 20, 1], device=cpu) = onnx::Sigmoid(%150)\n",
      "  %152 : Float(1, 256, 15, 20, strides=[76800, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%150, %151) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %153 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%152, %pretrained.7.conv.weight, %pretrained.7.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %154 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], device=cpu) = onnx::Sigmoid(%153)\n",
      "  %155 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%153, %154) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %156 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%155, %pretrained.8.cv1.conv.weight, %pretrained.8.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %157 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], device=cpu) = onnx::Sigmoid(%156)\n",
      "  %158 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%156, %157) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %159 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%158, %pretrained.8.m.0.cv1.conv.weight, %pretrained.8.m.0.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %160 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], device=cpu) = onnx::Sigmoid(%159)\n",
      "  %161 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%159, %160) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %162 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%161, %pretrained.8.m.0.cv2.conv.weight, %pretrained.8.m.0.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %163 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], device=cpu) = onnx::Sigmoid(%162)\n",
      "  %164 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%162, %163) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %165 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Add(%158, %164) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:105:0\n",
      "  %166 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%155, %pretrained.8.cv2.conv.weight, %pretrained.8.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %167 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], device=cpu) = onnx::Sigmoid(%166)\n",
      "  %168 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%166, %167) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %169 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%165, %168) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:139:0\n",
      "  %170 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%169, %pretrained.8.cv3.conv.weight, %pretrained.8.cv3.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %171 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], device=cpu) = onnx::Sigmoid(%170)\n",
      "  %172 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%170, %171) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %173 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%172, %pretrained.9.cv1.conv.weight, %pretrained.9.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %174 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], device=cpu) = onnx::Sigmoid(%173)\n",
      "  %175 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%173, %174) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %176 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::MaxPool[kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%175) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:719:0\n",
      "  %177 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::MaxPool[kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%176) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:719:0\n",
      "  %178 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::MaxPool[kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%177) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:719:0\n",
      "  %179 : Float(1, 1024, 8, 10, strides=[81920, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%175, %176, %177, %178) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:197:0\n",
      "  %180 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%179, %pretrained.9.cv2.conv.weight, %pretrained.9.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %181 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], device=cpu) = onnx::Sigmoid(%180)\n",
      "  %182 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%180, %181) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %183 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%182, %pretrained.10.conv.weight, %pretrained.10.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %184 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], device=cpu) = onnx::Sigmoid(%183)\n",
      "  %185 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%183, %184) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %186 : Float(1, 20480, strides=[20480, 1], requires_grad=0, device=cpu) = onnx::Flatten[axis=1](%185) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/flatten.py:42:0\n",
      "  return (%186)\n",
      "\n",
      "graph(%input.1 : Float(1, 20484, strides=[20484, 1], requires_grad=0, device=cpu),\n",
      "      %lin.0.weight : Float(512, 20484, strides=[20484, 1], requires_grad=1, device=cpu),\n",
      "      %lin.0.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %lin.2.weight : Float(35, 512, strides=[512, 1], requires_grad=1, device=cpu),\n",
      "      %lin.2.bias : Float(35, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %5 : Float(1, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.1, %lin.0.weight, %lin.0.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %6 : Float(1, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Relu(%5) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1297:0\n",
      "  %7 : Float(1, 35, strides=[35, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%6, %lin.2.weight, %lin.2.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  return (%7)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#save pytorch model\n",
    "torch.save(detector.state_dict(), 'detector.pt')\n",
    "torch.save(feature_extractor.state_dict(), 'feature_extractor.pt')\n",
    "\n",
    "#save the model so that opencv can load it\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "device = torch.device('cpu')\n",
    "detector.to(device)\n",
    "feature_extractor.to(device)\n",
    " \n",
    "onnx_detector_path = \"detector.onnx\"\n",
    "onnx_feature_extractor_path = \"feature_extractor.onnx\"\n",
    "\n",
    "# set the model to inference mode\n",
    "detector.eval()\n",
    "feature_extractor.eval()\n",
    " \n",
    "# Create some sample input in the shape this model expects \n",
    "# This is needed because the convertion forward pass the network once \n",
    "dummy_input = torch.randn(1, 3, 240, 320)\n",
    "dummy_input2 = torch.randn(1, 20484)\n",
    "torch.onnx.export(feature_extractor, dummy_input, onnx_feature_extractor_path, verbose=True)\n",
    "torch.onnx.export(detector, dummy_input2, onnx_detector_path, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:11<00:00,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[  -0.085596    0.058444      7.2527    0.071631    0.029917    -0.10753   -0.038321      0.0562     0.10364    0.083307      0.0144     0.18264   -0.030135    0.048837    0.068057    -0.05302  -0.0011943   -0.022427    0.043871    -0.10293    -0.08841  -0.0054706    -0.65493      3.1872     -7.2564      1.8444\n",
      "      -1.5973     -4.7095      13.277     -12.225      -11.98     -13.961     -14.774     -12.789     -13.977]]\n",
      "Predictions shape: (1, 35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#test with opencv\n",
    "sample_image = \"training_imgs/img_1.png\"\n",
    "images = [cv.imread(f\"training_imgs/img_{i+1}.png\") for i in range(100)]\n",
    " \n",
    "#The Magic:\n",
    "det =  cv.dnn.readNetFromONNX(onnx_detector_path) \n",
    "ext = cv.dnn.readNetFromONNX(onnx_feature_extractor_path)\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    image = images[i]\n",
    "    blob = cv.dnn.blobFromImage(image, 1.0, (320, 240),(0, 0, 0), swapRB=True, crop=False)\n",
    "    ext.setInput(blob)\n",
    "    features = ext.forward()\n",
    "    # print(features.shape)\n",
    "    action_vec = np.ones((1,4))\n",
    "    input = np.concatenate((features, action_vec), axis=1)\n",
    "    # print(input.shape)\n",
    "    det.setInput(input)\n",
    "    preds = det.forward()\n",
    "\n",
    "print(f\"Predictions: {preds}\")\n",
    "print(f\"Predictions shape: {preds.shape}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cee89b7c6bc96453738565335b56b694d8a30ac65e979633b683f8408c8233c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('dl_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
