{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px # this is another plotting library for interactive plot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, manifold # we will use the metrics and manifold learning modules from scikit-learn\n",
    "from pathlib import Path # to interact with file paths\n",
    "from PIL import Image # to interact with images\n",
    "from tqdm import tqdm # progress bar\n",
    "from pprint import pprint # pretty print (useful for a more readable print of objects like lists or dictionaries)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2 as cv\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Net and create Detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/irong/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-2-17 torch 1.10.0+cu113 CUDA:0 (NVIDIA GeForce GTX 950M, 2004MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Detector(\n",
       "  (lin): Sequential(\n",
       "    (0): Linear(in_features=20484, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=512, out_features=21, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True) #faster but less accurate\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True) \n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5n6', pretrained=True) \n",
    "# model = torch.hub.load('ultralytics/yolov3', 'yolov3') #bad \n",
    "model.to(device)\n",
    "\n",
    "# Analyze network\n",
    "\n",
    "# print(model)\n",
    "\n",
    "# for param_name, param in model.named_parameters():\n",
    "#     print(param_name)\n",
    "\n",
    "# for i, (k, v) in enumerate(model.named_parameters()):\n",
    "#     print(f'{i} - {k}')\n",
    "\n",
    "#https://github.com/ultralytics/yolov5/issues/1314\n",
    "\n",
    "#backnbone is layers 0->9\n",
    "\n",
    "backbone_layers = [f'model.{x}' for x in range(9)]\n",
    "\n",
    "backbone = nn.Sequential(\n",
    "    model.model.model.model[0],\n",
    "    model.model.model.model[1],\n",
    "    model.model.model.model[2],\n",
    "    model.model.model.model[3],\n",
    "    model.model.model.model[4],\n",
    "    model.model.model.model[5],\n",
    "    model.model.model.model[6],\n",
    "    model.model.model.model[7],\n",
    "    model.model.model.model[8],\n",
    "    model.model.model.model[9],\n",
    "    model.model.model.model[10],\n",
    "    )\n",
    "\n",
    "# print(backbone)\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, backbone): #(default for 640x320)\n",
    "        super().__init__()\n",
    "\n",
    "        ## Pretrained layers\n",
    "        self.pretrained = backbone\n",
    "\n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutions\n",
    "        x = self.pretrained(x)\n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "        return x\n",
    "\n",
    "class Detector(nn.Module):\n",
    "    def __init__(self, add_inputs=4, regr_out=22, class_out=13, features=76800): #(default for 640x320)\n",
    "        super().__init__()\n",
    "        ### Linear sections\n",
    "        self.lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=features+add_inputs, out_features=512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(in_features=512, out_features=regr_out+class_out),\n",
    "        )\n",
    "        # #regression output\n",
    "        # self.lin_regr = nn.Sequential(\n",
    "        #     # First linear layer\n",
    "        #     nn.Linear(in_features=1024, out_features=512),\n",
    "        #     nn.ReLU(True),\n",
    "        #     # nn.Dropout(p=0.5),\n",
    "        #     # Second linear\n",
    "        #     nn.Linear(in_features=512, out_features=regr_out)\n",
    "        # )\n",
    "        # # classification output\n",
    "        # self.lin_class = nn.Sequential(\n",
    "        #     # First linear layer\n",
    "        #     nn.Linear(in_features=1024, out_features=512),\n",
    "        #     nn.ReLU(True),\n",
    "        #     # nn.Dropout(p=0.5),\n",
    "        #     # Second linear\n",
    "        #     nn.Linear(in_features=512, out_features=class_out)\n",
    "        # )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "feature_extractor=FeatureExtractor(backbone)\n",
    "#define detector\n",
    "detector = Detector(add_inputs=4, regr_out=22-16+2, class_out=13, features=20480)\n",
    "\n",
    "#freeeze backbone\n",
    "for param in feature_extractor.pretrained.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "feature_extractor.to(device)\n",
    "detector.to(device)\n",
    "\n",
    "# #check\n",
    "# for param_name, param in detector.named_parameters():\n",
    "#     print('%s \\t- requires_grad=%s' % (param_name, param.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 240, 320])\n",
      "torch.Size([1, 20484])\n",
      "torch.Size([1, 21])\n"
     ]
    }
   ],
   "source": [
    "# test backbone\n",
    "#show the image with opencv\n",
    "img = cv.imread('tests/test_img.jpg')\n",
    "#resize to 480 x 640\n",
    "img = cv.resize(img, (320, 240))\n",
    "#convert to tensor\n",
    "img = torch.from_numpy(img).float().permute(2, 0, 1)\n",
    "#add dimension\n",
    "img = img.unsqueeze(0).to(device)\n",
    "print(img.shape)\n",
    "\n",
    "detector.eval()\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    data = torch.zeros(1, 4).to(device)\n",
    "    feat = feature_extractor(img)\n",
    "    input = torch.cat((feat, data), dim=1)\n",
    "    print(input.shape)\n",
    "    out = detector(input) \n",
    "    print(out.shape) # (320, 240)->torch.Size([1, 20480])\n",
    "                    # (640, 480)->torch.Size([1, 76800])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4949/4949 [00:00<00:00, 42978.64it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4949/4949 [00:00<00:00, 101716.10it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4949/4949 [00:20<00:00, 238.40it/s]\n"
     ]
    }
   ],
   "source": [
    "#dataset\n",
    "class CsvDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        class_labels = []\n",
    "        with open(folder+'/classification_labels.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            # Get x and y values from each line and append to self.data\n",
    "            labels = []\n",
    "            for i in tqdm(range(len(lines))):\n",
    "                line = lines[i]\n",
    "                sample = line.split(',')\n",
    "                #convert to float\n",
    "                label = np.array([float(s) for s in sample])\n",
    "                #convert to tensor\n",
    "                label = torch.from_numpy(label).float()\n",
    "                # img = img.unsqueeze(0)\n",
    "                class_labels.append(label)\n",
    "\n",
    "        input_data = []\n",
    "        with open(folder+'/input_data.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            # Get x and y values from each line and append to self.data\n",
    "            labels = []\n",
    "            for i in tqdm(range(len(lines))):\n",
    "                line = lines[i]\n",
    "                sample = line.split(',')\n",
    "                #convert to float\n",
    "                label = np.array([float(s) for s in sample])\n",
    "                #convert to tensor\n",
    "                label = torch.from_numpy(label).float()\n",
    "                # img = img.unsqueeze(0)\n",
    "                input_data.append(label)\n",
    "\n",
    "        #load labels\n",
    "        with open(folder+'/regression_labels.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            # Get x and y values from each line and append to self.data\n",
    "            labels = []\n",
    "            for i in tqdm(range(len(lines))):\n",
    "                line = lines[i]\n",
    "                sample = line.split(',')\n",
    "                #convert to float\n",
    "                label = np.array([float(s) for s in sample])\n",
    "                #convert to tensor\n",
    "                label = torch.from_numpy(label).float()\n",
    "                #load img\n",
    "                img = cv.imread(folder+f'/img_{i+1}.png')\n",
    "                img = cv.resize(img, (320, 240))\n",
    "                img = torch.from_numpy(img).float().permute(2, 0, 1)\n",
    "                # img = img.unsqueeze(0)\n",
    "                self.data.append((img, input_data[i], label, class_labels[i]))\n",
    "                \n",
    "    def __len__(self):\n",
    "        # The length of the dataset is simply the length of the self.data list\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Our sample is the element idx of the list self.data\n",
    "        sample = self.data[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "#create dataset\n",
    "train_dataset = CsvDataset(folder='training_imgs')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(ext, det, dataloader, class_loss_fn, regr_loss_fn, optimizer, device):\n",
    "    # Set the model to training mode\n",
    "    ext.eval() #dont train the extractor\n",
    "    det.train() #train detector\n",
    "    # Initialize the loss\n",
    "    train_loss_class = []\n",
    "    train_loss_regr = []\n",
    "\n",
    "    err_losses = []\n",
    "    dist_losses = []\n",
    "    curv_losses = []\n",
    "    bb_losses = []\n",
    "\n",
    "    # Loop over the training batches\n",
    "    for (img, input_data, regr_label, class_label) in dataloader:\n",
    "        # Move the input and target data to the selected device\n",
    "        img, input_data, regr_label, class_label = img.to(device), input_data.to(device), regr_label.to(device), class_label.to(device)\n",
    "        # Compute the features\n",
    "        features = ext(img)\n",
    "        #concatenate features and input_data\n",
    "        input = torch.cat((features, input_data), dim=1)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the output\n",
    "        output = det(input)\n",
    "\n",
    "        #regression 22 values\n",
    "        #classification: 3 states, 3 next states, 7 signs\n",
    "        regr_out = output[:, :22-16+2]\n",
    "        err_out = regr_out[:, :2]\n",
    "        dist_out = regr_out[:, 2]\n",
    "        curv_out = regr_out[:, 3]\n",
    "        bb_out = regr_out[:, 4:8]\n",
    "\n",
    "        err_label = regr_label[:, :2]\n",
    "        dist_label = regr_label[:, 2]\n",
    "        curv_label = regr_label[:, 3]\n",
    "        bb_label = regr_label[:, 4:8]\n",
    "\n",
    "        state_out = output[:, 22-16+2:25-16+2]\n",
    "        next_out = output[:, 25-16+2:28-16+2]\n",
    "        sign_out = output[:, 28-16+2:]\n",
    "        \n",
    "        state_label = class_label[:, :3]\n",
    "        next_label = class_label[:, 3:6]\n",
    "        sign_label = class_label[:, 6:]\n",
    "\n",
    "        # Compute the losses\n",
    "        # regr_loss = regr_loss_fn(regr_out, regr_label)\n",
    "\n",
    "        err_loss = 50.0*regr_loss_fn(err_out, err_label)\n",
    "        dist_loss = 0.1*regr_loss_fn(dist_out, dist_label)\n",
    "        curv_loss = 0.1*regr_loss_fn(curv_out, curv_label)\n",
    "        bb_loss = 1.0*regr_loss_fn(bb_out, bb_label)\n",
    "\n",
    "\n",
    "        state_loss = 0.5*class_loss_fn(state_out, state_label)\n",
    "        next_loss = 0.1*class_loss_fn(next_out, next_label)\n",
    "        sign_loss = 5.0*class_loss_fn(sign_out, sign_label)\n",
    "        loss = err_loss + dist_loss + curv_loss + bb_loss + state_loss + next_loss + sign_loss\n",
    "\n",
    "        \n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        #batch loss\n",
    "        c_loss = (state_loss + next_loss + sign_loss).detach().cpu().numpy()\n",
    "        train_loss_class.append(c_loss)\n",
    "        err_losses.append(err_loss.detach().cpu().numpy())\n",
    "        dist_losses.append(dist_loss.detach().cpu().numpy())\n",
    "        curv_losses.append(curv_loss.detach().cpu().numpy())\n",
    "        bb_losses.append(bb_loss.detach().cpu().numpy())\n",
    "    # Return the average training loss\n",
    "    train_loss_c = np.mean(train_loss_class)\n",
    "    err_loss = np.mean(err_losses)\n",
    "    dist_loss = np.mean(dist_losses)\n",
    "    curv_loss = np.mean(curv_losses)\n",
    "    bb_loss = np.mean(bb_losses)\n",
    "    # print(f\"Training loss: {train_loss}\")\n",
    "    return train_loss_c, err_loss, dist_loss, curv_loss, bb_loss\n",
    "\n",
    "def get_avg_loss(ext, det, dataloader, class_loss_fn, regr_loss_fn, device):\n",
    "    ext.eval()\n",
    "    det.eval()\n",
    "    class_losses = []\n",
    "    regr_losses = []\n",
    "    with torch.no_grad():\n",
    "        for (img, input_data, regr_label, class_label) in dataloader:\n",
    "            # Move the input and target data to the selected device\n",
    "            img, input_data, regr_label, class_label = img.to(device), input_data.to(device), regr_label.to(device), class_label.to(device)\n",
    "            # Compute the features\n",
    "            features = ext(img)\n",
    "            #concatenate features and input_data\n",
    "            input = torch.cat((features, input_data), dim=1)\n",
    "            # Compute the output\n",
    "            output = det(input)\n",
    "            \n",
    "            #regression 22 values\n",
    "            #classification: 3 states, 3 next states, 7 signs\n",
    "            regr_out = output[:, :22]\n",
    "            state_out = output[:, 22:25]\n",
    "            next_out = output[:, 25:28]\n",
    "            sign_out = output[:, 28:]\n",
    "            \n",
    "            state_label = class_label[:, :3]\n",
    "            next_label = class_label[:, 3:6]\n",
    "            sign_label = class_label[:, 6:]\n",
    "\n",
    "            # Compute the losses\n",
    "            regr_loss = regr_loss_fn(regr_out, regr_label)\n",
    "            state_loss = class_loss_fn(state_out, state_label)\n",
    "            next_loss = class_loss_fn(next_out, next_label)\n",
    "            sign_loss = class_loss_fn(sign_out, sign_label)\n",
    "            class_loss = state_loss + next_loss + sign_loss\n",
    "\n",
    "            class_losses.append(class_loss.detach().cpu().numpy())\n",
    "            regr_losses.append(regr_loss.detach().cpu().numpy())\n",
    "    # Return the accuracy and test loss\n",
    "    class_loss = np.mean(class_losses)\n",
    "    regr_loss = np.mean(regr_losses)\n",
    "    return class_loss, regr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "err_loss: 3.1153159141540527\n",
      "dist_loss: 1.3082064390182495\n",
      "curv_loss: 0.008021161891520023\n",
      "bb_loss: 0.09954803436994553\n",
      "Classification loss: 6.209814548492432\n",
      "Epoch 2/10\n",
      "err_loss: 0.2070363610982895\n",
      "dist_loss: 0.6833064556121826\n",
      "curv_loss: 0.0012923658359795809\n",
      "bb_loss: 0.03912626579403877\n",
      "Classification loss: 5.014316558837891\n",
      "Epoch 3/10\n",
      "err_loss: 0.12920410931110382\n",
      "dist_loss: 0.49703484773635864\n",
      "curv_loss: 0.0007932021399028599\n",
      "bb_loss: 0.030636146664619446\n",
      "Classification loss: 4.68255090713501\n",
      "Epoch 4/10\n",
      "err_loss: 0.10391083359718323\n",
      "dist_loss: 0.3599572479724884\n",
      "curv_loss: 0.0006752338958904147\n",
      "bb_loss: 0.027941979467868805\n",
      "Classification loss: 4.378341197967529\n",
      "Epoch 5/10\n",
      "err_loss: 0.08824069797992706\n",
      "dist_loss: 0.29547324776649475\n",
      "curv_loss: 0.0006635162280872464\n",
      "bb_loss: 0.02635379508137703\n",
      "Classification loss: 4.174495220184326\n",
      "Epoch 6/10\n",
      "err_loss: 0.08015993237495422\n",
      "dist_loss: 0.24517200887203217\n",
      "curv_loss: 0.0005764518864452839\n",
      "bb_loss: 0.024186231195926666\n",
      "Classification loss: 3.9104137420654297\n",
      "Epoch 7/10\n",
      "err_loss: 0.059878066182136536\n",
      "dist_loss: 0.20318928360939026\n",
      "curv_loss: 0.00035250731161795557\n",
      "bb_loss: 0.023532992228865623\n",
      "Classification loss: 3.617849349975586\n",
      "Epoch 8/10\n",
      "err_loss: 0.05969207361340523\n",
      "dist_loss: 0.1955307424068451\n",
      "curv_loss: 0.00019705526938196272\n",
      "bb_loss: 0.021052932366728783\n",
      "Classification loss: 3.3251376152038574\n",
      "Epoch 9/10\n",
      "err_loss: 0.058610767126083374\n",
      "dist_loss: 0.16584430634975433\n",
      "curv_loss: 0.00010917909094132483\n",
      "bb_loss: 0.019307810813188553\n",
      "Classification loss: 3.028773546218872\n",
      "Epoch 10/10\n",
      "err_loss: 0.07032674551010132\n",
      "dist_loss: 0.17758524417877197\n",
      "curv_loss: 8.399322541663423e-05\n",
      "bb_loss: 0.018967626616358757\n",
      "Classification loss: 2.828648328781128\n"
     ]
    }
   ],
   "source": [
    "# #load models\n",
    "detector.load_state_dict(torch.load('detector.pt'))\n",
    "feature_extractor.load_state_dict(torch.load('feature_extractor.pt'))\n",
    "\n",
    "#parameters\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "optimizer = torch.optim.Adam(detector.parameters(), lr=lr)\n",
    "regr_loss_fn = nn.MSELoss()\n",
    "class_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss_c, err_loss, dist_loss, curv_loss, bb_loss = train_epoch(feature_extractor, detector, train_dataloader, class_loss_fn, regr_loss_fn, optimizer, device)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"err_loss: {err_loss}\")\n",
    "    print(f\"dist_loss: {dist_loss}\")\n",
    "    print(f\"curv_loss: {curv_loss}\")\n",
    "    print(f\"bb_loss: {bb_loss}\")\n",
    "    print(f\"Classification loss: {train_loss_c}\")\n",
    "    torch.save(detector.state_dict(), 'detector.pt')\n",
    "    torch.save(feature_extractor.state_dict(), 'feature_extractor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4575/4575 [00:00<00:00, 24681.77it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4575/4575 [00:00<00:00, 37421.24it/s]\n",
      "  0%|          | 0/4575 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) /tmp/pip-req-build-3129w7z7/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_207608/2154762253.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCsvDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test_imgs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#get accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_207608/3849597537.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, folder, transform)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;31m#load img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34mf'/img_{i+1}.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;31m# img = img.unsqueeze(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.4) /tmp/pip-req-build-3129w7z7/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "test_dataset = CsvDataset(folder='test_imgs')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "#get accuracy\n",
    "train_class_loss, train_regr_loss = get_avg_loss(feature_extractor, detector, train_dataloader, class_loss_fn, regr_loss_fn, device)\n",
    "test_class_loss, test_regr_loss = get_avg_loss(feature_extractor, detector, test_dataloader, class_loss_fn, regr_loss_fn, device)\n",
    "\n",
    "print(f\"Training classification loss: {train_class_loss}\")\n",
    "print(f\"Training regression loss: {train_regr_loss}\\n\")\n",
    "print(f\"Testing classification loss: {test_class_loss}\")\n",
    "print(f\"Testing regression loss: {test_regr_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 240, 320])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input.1 : Float(1, 3, 240, 320, strides=[230400, 76800, 320, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.0.conv.weight : Float(32, 3, 6, 6, strides=[108, 36, 6, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.0.conv.bias : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.1.conv.weight : Float(64, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.1.conv.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.cv1.conv.weight : Float(32, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.cv1.conv.bias : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.cv2.conv.weight : Float(32, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.cv2.conv.bias : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.cv3.conv.weight : Float(64, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.cv3.conv.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.m.0.cv1.conv.weight : Float(32, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.m.0.cv1.conv.bias : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.m.0.cv2.conv.weight : Float(32, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.2.m.0.cv2.conv.bias : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.3.conv.weight : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.3.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.cv1.conv.weight : Float(64, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.cv1.conv.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.cv2.conv.weight : Float(64, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.cv2.conv.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.cv3.conv.weight : Float(128, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.cv3.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.m.0.cv1.conv.weight : Float(64, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.m.0.cv1.conv.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.m.0.cv2.conv.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.m.0.cv2.conv.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.m.1.cv1.conv.weight : Float(64, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.m.1.cv1.conv.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.m.1.cv2.conv.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.4.m.1.cv2.conv.bias : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.5.conv.weight : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.5.conv.bias : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.cv1.conv.weight : Float(128, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.cv1.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.cv2.conv.weight : Float(128, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.cv2.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.cv3.conv.weight : Float(256, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.cv3.conv.bias : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.0.cv1.conv.weight : Float(128, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.0.cv1.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.0.cv2.conv.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.0.cv2.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.1.cv1.conv.weight : Float(128, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.1.cv1.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.1.cv2.conv.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.1.cv2.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.2.cv1.conv.weight : Float(128, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.2.cv1.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.2.cv2.conv.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.6.m.2.cv2.conv.bias : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.7.conv.weight : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.7.conv.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.cv1.conv.weight : Float(256, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.cv1.conv.bias : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.cv2.conv.weight : Float(256, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.cv2.conv.bias : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.cv3.conv.weight : Float(512, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.cv3.conv.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.m.0.cv1.conv.weight : Float(256, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.m.0.cv1.conv.bias : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.m.0.cv2.conv.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.8.m.0.cv2.conv.bias : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.9.cv1.conv.weight : Float(256, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.9.cv1.conv.bias : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.9.cv2.conv.weight : Float(512, 1024, 1, 1, strides=[1024, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.9.cv2.conv.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %pretrained.10.conv.weight : Float(256, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %pretrained.10.conv.bias : Float(256, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %69 : Float(1, 32, 120, 160, strides=[614400, 19200, 160, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[6, 6], pads=[2, 2, 2, 2], strides=[2, 2]](%input.1, %pretrained.0.conv.weight, %pretrained.0.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %70 : Float(1, 32, 120, 160, strides=[614400, 19200, 160, 1], device=cpu) = onnx::Sigmoid(%69)\n",
      "  %71 : Float(1, 32, 120, 160, strides=[614400, 19200, 160, 1], requires_grad=0, device=cpu) = onnx::Mul(%69, %70) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %72 : Float(1, 64, 60, 80, strides=[307200, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%71, %pretrained.1.conv.weight, %pretrained.1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %73 : Float(1, 64, 60, 80, strides=[307200, 4800, 80, 1], device=cpu) = onnx::Sigmoid(%72)\n",
      "  %74 : Float(1, 64, 60, 80, strides=[307200, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Mul(%72, %73) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %75 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%74, %pretrained.2.cv1.conv.weight, %pretrained.2.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %76 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], device=cpu) = onnx::Sigmoid(%75)\n",
      "  %77 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Mul(%75, %76) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %78 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%77, %pretrained.2.m.0.cv1.conv.weight, %pretrained.2.m.0.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %79 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], device=cpu) = onnx::Sigmoid(%78)\n",
      "  %80 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Mul(%78, %79) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %81 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%80, %pretrained.2.m.0.cv2.conv.weight, %pretrained.2.m.0.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %82 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], device=cpu) = onnx::Sigmoid(%81)\n",
      "  %83 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Mul(%81, %82) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %84 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Add(%77, %83) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:105:0\n",
      "  %85 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%74, %pretrained.2.cv2.conv.weight, %pretrained.2.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %86 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], device=cpu) = onnx::Sigmoid(%85)\n",
      "  %87 : Float(1, 32, 60, 80, strides=[153600, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Mul(%85, %86) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %88 : Float(1, 64, 60, 80, strides=[307200, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%84, %87) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:139:0\n",
      "  %89 : Float(1, 64, 60, 80, strides=[307200, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%88, %pretrained.2.cv3.conv.weight, %pretrained.2.cv3.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %90 : Float(1, 64, 60, 80, strides=[307200, 4800, 80, 1], device=cpu) = onnx::Sigmoid(%89)\n",
      "  %91 : Float(1, 64, 60, 80, strides=[307200, 4800, 80, 1], requires_grad=0, device=cpu) = onnx::Mul(%89, %90) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %92 : Float(1, 128, 30, 40, strides=[153600, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%91, %pretrained.3.conv.weight, %pretrained.3.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %93 : Float(1, 128, 30, 40, strides=[153600, 1200, 40, 1], device=cpu) = onnx::Sigmoid(%92)\n",
      "  %94 : Float(1, 128, 30, 40, strides=[153600, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Mul(%92, %93) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %95 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%94, %pretrained.4.cv1.conv.weight, %pretrained.4.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %96 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], device=cpu) = onnx::Sigmoid(%95)\n",
      "  %97 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Mul(%95, %96) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %98 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%97, %pretrained.4.m.0.cv1.conv.weight, %pretrained.4.m.0.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %99 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], device=cpu) = onnx::Sigmoid(%98)\n",
      "  %100 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Mul(%98, %99) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %101 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%100, %pretrained.4.m.0.cv2.conv.weight, %pretrained.4.m.0.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %102 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], device=cpu) = onnx::Sigmoid(%101)\n",
      "  %103 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Mul(%101, %102) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %104 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Add(%97, %103) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:105:0\n",
      "  %105 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%104, %pretrained.4.m.1.cv1.conv.weight, %pretrained.4.m.1.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %106 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], device=cpu) = onnx::Sigmoid(%105)\n",
      "  %107 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Mul(%105, %106) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %108 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%107, %pretrained.4.m.1.cv2.conv.weight, %pretrained.4.m.1.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %109 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], device=cpu) = onnx::Sigmoid(%108)\n",
      "  %110 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Mul(%108, %109) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %111 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Add(%104, %110) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:105:0\n",
      "  %112 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%94, %pretrained.4.cv2.conv.weight, %pretrained.4.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %113 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], device=cpu) = onnx::Sigmoid(%112)\n",
      "  %114 : Float(1, 64, 30, 40, strides=[76800, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Mul(%112, %113) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %115 : Float(1, 128, 30, 40, strides=[153600, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%111, %114) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:139:0\n",
      "  %116 : Float(1, 128, 30, 40, strides=[153600, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%115, %pretrained.4.cv3.conv.weight, %pretrained.4.cv3.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %117 : Float(1, 128, 30, 40, strides=[153600, 1200, 40, 1], device=cpu) = onnx::Sigmoid(%116)\n",
      "  %118 : Float(1, 128, 30, 40, strides=[153600, 1200, 40, 1], requires_grad=0, device=cpu) = onnx::Mul(%116, %117) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %119 : Float(1, 256, 15, 20, strides=[76800, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%118, %pretrained.5.conv.weight, %pretrained.5.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %120 : Float(1, 256, 15, 20, strides=[76800, 300, 20, 1], device=cpu) = onnx::Sigmoid(%119)\n",
      "  %121 : Float(1, 256, 15, 20, strides=[76800, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%119, %120) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %122 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%121, %pretrained.6.cv1.conv.weight, %pretrained.6.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %123 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], device=cpu) = onnx::Sigmoid(%122)\n",
      "  %124 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%122, %123) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %125 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%124, %pretrained.6.m.0.cv1.conv.weight, %pretrained.6.m.0.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %126 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], device=cpu) = onnx::Sigmoid(%125)\n",
      "  %127 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%125, %126) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %128 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%127, %pretrained.6.m.0.cv2.conv.weight, %pretrained.6.m.0.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %129 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], device=cpu) = onnx::Sigmoid(%128)\n",
      "  %130 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%128, %129) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %131 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Add(%124, %130) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:105:0\n",
      "  %132 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%131, %pretrained.6.m.1.cv1.conv.weight, %pretrained.6.m.1.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %133 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], device=cpu) = onnx::Sigmoid(%132)\n",
      "  %134 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%132, %133) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %135 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%134, %pretrained.6.m.1.cv2.conv.weight, %pretrained.6.m.1.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %136 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], device=cpu) = onnx::Sigmoid(%135)\n",
      "  %137 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%135, %136) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %138 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Add(%131, %137) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:105:0\n",
      "  %139 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%138, %pretrained.6.m.2.cv1.conv.weight, %pretrained.6.m.2.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %140 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], device=cpu) = onnx::Sigmoid(%139)\n",
      "  %141 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%139, %140) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %142 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%141, %pretrained.6.m.2.cv2.conv.weight, %pretrained.6.m.2.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %143 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], device=cpu) = onnx::Sigmoid(%142)\n",
      "  %144 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%142, %143) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %145 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Add(%138, %144) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:105:0\n",
      "  %146 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%121, %pretrained.6.cv2.conv.weight, %pretrained.6.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %147 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], device=cpu) = onnx::Sigmoid(%146)\n",
      "  %148 : Float(1, 128, 15, 20, strides=[38400, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%146, %147) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %149 : Float(1, 256, 15, 20, strides=[76800, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%145, %148) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:139:0\n",
      "  %150 : Float(1, 256, 15, 20, strides=[76800, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%149, %pretrained.6.cv3.conv.weight, %pretrained.6.cv3.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %151 : Float(1, 256, 15, 20, strides=[76800, 300, 20, 1], device=cpu) = onnx::Sigmoid(%150)\n",
      "  %152 : Float(1, 256, 15, 20, strides=[76800, 300, 20, 1], requires_grad=0, device=cpu) = onnx::Mul(%150, %151) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %153 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%152, %pretrained.7.conv.weight, %pretrained.7.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %154 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], device=cpu) = onnx::Sigmoid(%153)\n",
      "  %155 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%153, %154) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %156 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%155, %pretrained.8.cv1.conv.weight, %pretrained.8.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %157 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], device=cpu) = onnx::Sigmoid(%156)\n",
      "  %158 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%156, %157) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %159 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%158, %pretrained.8.m.0.cv1.conv.weight, %pretrained.8.m.0.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %160 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], device=cpu) = onnx::Sigmoid(%159)\n",
      "  %161 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%159, %160) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %162 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%161, %pretrained.8.m.0.cv2.conv.weight, %pretrained.8.m.0.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %163 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], device=cpu) = onnx::Sigmoid(%162)\n",
      "  %164 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%162, %163) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %165 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Add(%158, %164) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:105:0\n",
      "  %166 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%155, %pretrained.8.cv2.conv.weight, %pretrained.8.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %167 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], device=cpu) = onnx::Sigmoid(%166)\n",
      "  %168 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%166, %167) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %169 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%165, %168) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:139:0\n",
      "  %170 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%169, %pretrained.8.cv3.conv.weight, %pretrained.8.cv3.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %171 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], device=cpu) = onnx::Sigmoid(%170)\n",
      "  %172 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%170, %171) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %173 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%172, %pretrained.9.cv1.conv.weight, %pretrained.9.cv1.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %174 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], device=cpu) = onnx::Sigmoid(%173)\n",
      "  %175 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%173, %174) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %176 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::MaxPool[kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%175) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:719:0\n",
      "  %177 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::MaxPool[kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%176) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:719:0\n",
      "  %178 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::MaxPool[kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%177) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:719:0\n",
      "  %179 : Float(1, 1024, 8, 10, strides=[81920, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%175, %176, %177, %178) # /home/irong/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:197:0\n",
      "  %180 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%179, %pretrained.9.cv2.conv.weight, %pretrained.9.cv2.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %181 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], device=cpu) = onnx::Sigmoid(%180)\n",
      "  %182 : Float(1, 512, 8, 10, strides=[40960, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%180, %181) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %183 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%182, %pretrained.10.conv.weight, %pretrained.10.conv.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %184 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], device=cpu) = onnx::Sigmoid(%183)\n",
      "  %185 : Float(1, 256, 8, 10, strides=[20480, 80, 10, 1], requires_grad=0, device=cpu) = onnx::Mul(%183, %184) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1898:0\n",
      "  %186 : Float(1, 20480, strides=[20480, 1], requires_grad=0, device=cpu) = onnx::Flatten[axis=1](%185) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/modules/flatten.py:42:0\n",
      "  return (%186)\n",
      "\n",
      "graph(%input.1 : Float(1, 20484, strides=[20484, 1], requires_grad=0, device=cpu),\n",
      "      %lin.0.weight : Float(512, 20484, strides=[20484, 1], requires_grad=1, device=cpu),\n",
      "      %lin.0.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %lin.2.weight : Float(21, 512, strides=[512, 1], requires_grad=1, device=cpu),\n",
      "      %lin.2.bias : Float(21, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %5 : Float(1, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.1, %lin.0.weight, %lin.0.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  %6 : Float(1, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Relu(%5) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1297:0\n",
      "  %7 : Float(1, 21, strides=[21, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%6, %lin.2.weight, %lin.2.bias) # /home/irong/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/nn/functional.py:1848:0\n",
      "  return (%7)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#save pytorch model\n",
    "torch.save(detector.state_dict(), 'detector.pt')\n",
    "torch.save(feature_extractor.state_dict(), 'feature_extractor.pt')\n",
    "\n",
    "#save the model so that opencv can load it\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "device = torch.device('cpu')\n",
    "detector.to(device)\n",
    "feature_extractor.to(device)\n",
    " \n",
    "onnx_detector_path = \"detector.onnx\"\n",
    "onnx_feature_extractor_path = \"feature_extractor.onnx\"\n",
    "\n",
    "# set the model to inference mode\n",
    "detector.eval()\n",
    "feature_extractor.eval()\n",
    " \n",
    "# Create some sample input in the shape this model expects \n",
    "# This is needed because the convertion forward pass the network once \n",
    "dummy_input = torch.randn(1, 3, 240, 320)\n",
    "dummy_input2 = torch.randn(1, 20484)\n",
    "torch.onnx.export(feature_extractor, dummy_input, onnx_feature_extractor_path, verbose=True)\n",
    "torch.onnx.export(detector, dummy_input2, onnx_detector_path, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:13<00:00,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[   0.048059    -0.26342      10.508   -0.021518     0.25527     0.13125     0.18168   -0.054462     -3.0306      2.6176      -7.293      5.4607      -1.801     -7.6935      2.5046      1.7745     0.95507    -0.13515     0.25913     0.10769      1.9124]]\n",
      "Predictions shape: (1, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#test with opencv\n",
    "sample_image = \"training_imgs/img_1.png\"\n",
    "images = [cv.imread(f\"training_imgs/img_{i+1}.png\") for i in range(100)]\n",
    " \n",
    "#The Magic:\n",
    "det =  cv.dnn.readNetFromONNX(onnx_detector_path) \n",
    "ext = cv.dnn.readNetFromONNX(onnx_feature_extractor_path)\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    image = images[i]\n",
    "    blob = cv.dnn.blobFromImage(image, 1.0, (320, 240),(0, 0, 0), swapRB=True, crop=False)\n",
    "    ext.setInput(blob)\n",
    "    features = ext.forward()\n",
    "    # print(features.shape)\n",
    "    action_vec = np.ones((1,4))\n",
    "    input = np.concatenate((features, action_vec), axis=1)\n",
    "    # print(input.shape)\n",
    "    det.setInput(input)\n",
    "    preds = det.forward()\n",
    "\n",
    "print(f\"Predictions: {preds}\")\n",
    "print(f\"Predictions shape: {preds.shape}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cee89b7c6bc96453738565335b56b694d8a30ac65e979633b683f8408c8233c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('dl_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
