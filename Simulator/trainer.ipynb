{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px # this is another plotting library for interactive plot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, manifold # we will use the metrics and manifold learning modules from scikit-learn\n",
    "from pathlib import Path # to interact with file paths\n",
    "from PIL import Image # to interact with images\n",
    "from tqdm import tqdm # progress bar\n",
    "from pprint import pprint # pretty print (useful for a more readable print of objects like lists or dictionaries)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2 as cv\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Net and create Detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True) #faster but less accurate\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True) \n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5n6', pretrained=True) \n",
    "# model = torch.hub.load('ultralytics/yolov3', 'yolov3') #bad \n",
    "model.to(device)\n",
    "\n",
    "# Analyze network\n",
    "\n",
    "# print(model)\n",
    "\n",
    "# for param_name, param in model.named_parameters():\n",
    "#     print(param_name)\n",
    "\n",
    "# for i, (k, v) in enumerate(model.named_parameters()):\n",
    "#     print(f'{i} - {k}')\n",
    "\n",
    "#https://github.com/ultralytics/yolov5/issues/1314\n",
    "\n",
    "#backnbone is layers 0->9\n",
    "\n",
    "backbone_layers = [f'model.{x}' for x in range(9)]\n",
    "\n",
    "backbone = nn.Sequential(\n",
    "    model.model.model.model[0],\n",
    "    model.model.model.model[1],\n",
    "    model.model.model.model[2],\n",
    "    model.model.model.model[3],\n",
    "    model.model.model.model[4],\n",
    "    model.model.model.model[5],\n",
    "    model.model.model.model[6],\n",
    "    model.model.model.model[7],\n",
    "    model.model.model.model[8],\n",
    "    model.model.model.model[9],\n",
    "    model.model.model.model[10],\n",
    "    )\n",
    "\n",
    "# print(backbone)\n",
    "\n",
    "class Detector(nn.Module):\n",
    "    def __init__(self, backbone, outputs, features=76800): #(default for 640x320)\n",
    "        super().__init__()\n",
    "\n",
    "        ## Pretrained layers\n",
    "        self.pretrained = backbone\n",
    "\n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "        ### Linear section\n",
    "        self.lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=features, out_features=512),\n",
    "            nn.ReLU(True),\n",
    "            # nn.Dropout(p=0.5),\n",
    "            # Second linear\n",
    "            nn.Linear(in_features=512, out_features=outputs),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply convolutions\n",
    "        x = self.pretrained(x)\n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "        # # Apply linear layers\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "#define detector\n",
    "detector = Detector(backbone, outputs=2, features=20480)\n",
    "\n",
    "\n",
    "#freeeze backbone\n",
    "for param in detector.pretrained.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "detector.to(device)\n",
    "\n",
    "# #check\n",
    "# for param_name, param in detector.named_parameters():\n",
    "#     print('%s \\t- requires_grad=%s' % (param_name, param.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test backbone\n",
    "#show the image with opencv\n",
    "img = cv.imread('tests/test_img.jpg')\n",
    "#resize to 480 x 640\n",
    "img = cv.resize(img, (320, 240))\n",
    "#convert to tensor\n",
    "img = torch.from_numpy(img).float().permute(2, 0, 1)\n",
    "#add dimension\n",
    "img = img.unsqueeze(0).to(device)\n",
    "\n",
    "detector.eval()\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    out = detector(img) \n",
    "    print(out.shape) # (320, 240)->torch.Size([1, 20480])\n",
    "                    # (640, 480)->torch.Size([1, 76800])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "class CsvDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        #load labels\n",
    "        with open(folder+'/labels.csv', 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            lines = lines[0:-1] #remove footer\n",
    "            # Get x and y values from each line and append to self.data\n",
    "            labels = []\n",
    "            for i in tqdm(range(len(lines))):\n",
    "                line = lines[i]\n",
    "                sample = line.split(',')\n",
    "                #convert to float\n",
    "                label = np.array([float(sample[0]), float(sample[1])])\n",
    "                #convert to tensor\n",
    "                label = torch.from_numpy(label).float()\n",
    "                #load img\n",
    "                img = cv.imread(folder+f'/img_{i+1}.png')\n",
    "                img = cv.resize(img, (320, 240))\n",
    "                img = torch.from_numpy(img).float().permute(2, 0, 1)\n",
    "                # img = img.unsqueeze(0)\n",
    "                self.data.append((img, label))\n",
    "                \n",
    "    def __len__(self):\n",
    "        # The length of the dataset is simply the length of the self.data list\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Our sample is the element idx of the list self.data\n",
    "        sample = self.data[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "#create dataset\n",
    "train_dataset = CsvDataset(folder='training_imgs')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, dataloader, loss_fn, optimizer, device):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    # Initialize the loss\n",
    "    train_loss = []\n",
    "    # Loop over the training batches\n",
    "    for (data, label) in dataloader:\n",
    "        # Move the input and target data to the selected device\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the output\n",
    "        output = model(data)\n",
    "        assert output.shape == label.shape\n",
    "        # Compute the loss\n",
    "        loss = loss_fn(output, label)\n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        #batch loss\n",
    "        loss_batch = loss.detach().cpu().numpy()\n",
    "        train_loss.append(loss_batch)\n",
    "    # Return the average training loss\n",
    "    train_loss = np.mean(train_loss)\n",
    "    # print(f\"Training loss: {train_loss}\")\n",
    "    return train_loss\n",
    "\n",
    "def get_avg_loss(net, dataloader, loss_fn, device):\n",
    "    net.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for (data, label) in tqdm(dataloader):\n",
    "            # Move the input and target data to the selected device\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            # Compute the output\n",
    "            output = net(data)\n",
    "            assert output.shape == label.shape\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(output, label)\n",
    "            losses.append(loss.detach().cpu().numpy())\n",
    "    # Return the accuracy and test loss\n",
    "    test_loss = np.mean(losses)\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "detector.load_state_dict(torch.load('detector.pt'))\n",
    "\n",
    "#parameters\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "optimizer = torch.optim.Adam(detector.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(detector, train_dataloader, loss_fn, optimizer, device)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Training loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "test_dataset = CsvDataset(folder='test_imgs')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "#get accuracy\n",
    "train_loss = get_avg_loss(detector, train_dataloader, loss_fn, device)\n",
    "test_loss = get_avg_loss(detector, test_dataloader, loss_fn, device)\n",
    "\n",
    "print(f\"Training loss: {train_loss}\")\n",
    "print(f\"Testing loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset.data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save pytorch model\n",
    "torch.save(detector.state_dict(), 'detector.pt')\n",
    "\n",
    "#save the model so that opencv can load it\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "device = torch.device('cpu')\n",
    "detector.to(device)\n",
    " \n",
    "onnx_model_path = \"model_test.onnx\"\n",
    "\n",
    "# set the model to inference mode\n",
    "detector.eval()\n",
    " \n",
    "# Create some sample input in the shape this model expects \n",
    "# This is needed because the convertion forward pass the network once \n",
    "dummy_input = torch.randn(1, 3, 240, 320)\n",
    "torch.onnx.export(detector, dummy_input, onnx_model_path, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test with opencv\n",
    "sample_image = \"training_imgs/img_1.png\"\n",
    "images = [cv.imread(f\"training_imgs/img_{i+1}.png\") for i in range(100)]\n",
    " \n",
    "#The Magic:\n",
    "net =  cv.dnn.readNetFromONNX(onnx_model_path) \n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    image = images[i]\n",
    "    blob = cv.dnn.blobFromImage(image, 1.0, (320, 240),(0, 0, 0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    preds = net.forward()\n",
    "\n",
    "print (\"Predictions: \", preds)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cee89b7c6bc96453738565335b56b694d8a30ac65e979633b683f8408c8233c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('dl_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
